{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ef89331",
   "metadata": {},
   "source": [
    "# Part 1: Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808610f2",
   "metadata": {},
   "source": [
    "## Load Cifar10 dataset from tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5937fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "plt.imshow(x_train[21])\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "#One-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e56ceb",
   "metadata": {},
   "source": [
    "### Let's print some information about the dataset\n",
    "Print the the dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93037f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f279630",
   "metadata": {},
   "source": [
    "## Construct the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout,Flatten, Dense, Activation, BatchNormalization, Conv2D, MaxPooling2D,InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "input_shape = (32, 32, 3)\n",
    "model.add(InputLayer(input_shape=input_shape))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(activation='softmax'))\n",
    "\n",
    "\"\"\"\n",
    "model = Sequential()\n",
    "input_shape=(32, 32, 3)\n",
    "model.add(InputLayer(input_shape=input_shape))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(activation='softmax'))\n",
    "\"\"\"\n",
    "model.summary()\n",
    "model.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55509be5",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We'll use Adam optimizer with categorical crossentropy loss.\n",
    "The callbacks will decay the learning rate and save the model into a directory 'model_mnist_cnn'\n",
    "The model isn't very complex, so this should just take a few minutes even on the CPU.\n",
    "If you've restarted the notebook kernel after training once, set `train = False` to load the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1778b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from callbacks import all_callbacks\n",
    "import os\n",
    "train = True\n",
    "\n",
    "\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks = all_callbacks(stop_patience = 1000,\n",
    "                              lr_factor = 0.5,\n",
    "                              lr_patience = 10,\n",
    "                              lr_epsilon = 0.000001,\n",
    "                              lr_cooldown = 2,\n",
    "                              lr_minimum = 0.0000001,\n",
    "                              outputDir = 'model_cifar10_cnn')\n",
    "    model.fit(x_train, y_train, batch_size=128,\n",
    "              epochs=100, validation_data=(x_test, y_test), shuffle=True,\n",
    "              callbacks = callbacks.callbacks)\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    model = load_model('model_cifar10_cnn/KERAS_check_best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc4dfe",
   "metadata": {},
   "source": [
    "## Check performance\n",
    "Check the accuracy and make a ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "cifar10_classes=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "y_keras = model.predict(x_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "plt.figure(figsize=(9,9))\n",
    "_ = plotting.makeRoc(y_test, y_keras, cifar10_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344dcec1",
   "metadata": {},
   "source": [
    "# Convert the model to FPGA firmware with hls4ml\n",
    "Now we will go through the steps to convert the model we trained to a low-latency optimized FPGA firmware with hls4ml.\n",
    "First, we will evaluate its classification performance to make sure we haven't lost accuracy using the fixed-point data types. \n",
    "Then we will synthesize the model with Vivado HLS and check the metrics of latency and FPGA resource usage.\n",
    "\n",
    "## Make an hls4ml config & model\n",
    "The hls4ml Neural Network inference library is controlled through a configuration dictionary.\n",
    "In this example we'll use the most simple variation, later exercises will look at more advanced configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93656403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "from hls4ml.converters.keras_to_hls import keras_to_hls\n",
    "\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "config['Backend']='VivadoAccelerator'\n",
    "config['OutputDir'] = 'cifar10-hls-test'\n",
    "config['ProjectName'] = 'myproject_cifar10_cnn'\n",
    "config['XilinxPart']= 'xczu7ev-ffvc1156-2-e'\n",
    "config['Board'] = 'zcu104'\n",
    "config['ClockPeriod'] = 5\n",
    "config['IOType'] = 'io_stream'\n",
    "config['HLSConfig']={}\n",
    "config['HLSConfig']['Model']={}\n",
    "config['HLSConfig']['Model']=config['Model']\n",
    "config['HLSConfig']['LayerName']=config['LayerName']\n",
    "del config['Model']\n",
    "del config['LayerName']\n",
    "config['AcceleratorConfig']={}\n",
    "config['AcceleratorConfig']['Interface'] = 'axi_stream'\n",
    "config['AcceleratorConfig']['Driver'] = 'python'\n",
    "config['AcceleratorConfig']['Precision']={}\n",
    "config['AcceleratorConfig']['Precision']['Input']= 'float'\n",
    "config['AcceleratorConfig']['Precision']['Output']= 'float'\n",
    "config['KerasModel'] = model\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "hls_model = keras_to_hls(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7082db2",
   "metadata": {},
   "source": [
    "Let's visualise what we created. The model architecture is shown, annotated with the shape and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6a1c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e325b2d",
   "metadata": {},
   "source": [
    "## Compile, predict\n",
    "Now we need to check that this model performance is still good. We compile the hls_model, and then use `hls_model.predict` to execute the FPGA firmware with bit-accurate emulation on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa95932",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()\n",
    "x_test = np.ascontiguousarray(x_test)\n",
    "y_hls4ml = hls_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa33d0",
   "metadata": {},
   "source": [
    "## Compare\n",
    "That was easy! Now let's see how the performance compares to Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b11fcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_hls4ml = accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls4ml, axis=1))\n",
    "acc_keras=accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))\n",
    "print('Accuracy hls4ml:     {}'.format(acc_hls4ml))\n",
    "print('Accuracy keras:      {}'.format(acc_keras))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(y_test, y_keras, cifar10_classes)\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.makeRoc(y_test, y_hls4ml, cifar10_classes, linestyle='--')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['keras', 'hls4ml'],\n",
    "            loc='lower right', frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c872268",
   "metadata": {},
   "source": [
    "## Synthesize\n",
    "Now we'll actually use Vivado HLS to synthesize the model. We can run the build using a method of our `hls_model` object.\n",
    "After running this step, we can integrate the generated IP into a workflow to compile for a specific FPGA board.\n",
    "In this case, we'll just review the reports that Vivado HLS generates, checking the latency and resource usage.\n",
    "\n",
    "**This can take several minutes.**\n",
    "\n",
    "While the C-Synthesis is running, we can monitor the progress looking at the log file by opening a terminal from the notebook home, and executing:\n",
    "\n",
    "`tail -f mnist-hls-test/vivado_hls.log`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc2dd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] = '/workspace/home/Xilinx/Vivado/2019.2/bin:' + os.environ['PATH']\n",
    "hls_model.build(csim=False,synth=True,export=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c92c7",
   "metadata": {},
   "source": [
    "## Check the reports\n",
    "Print out the reports generated by Vivado HLS. Pay attention to the Latency and the 'Utilization Estimates' sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f691d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "from hls4ml.converters.keras_to_hls import keras_to_hls\n",
    "\n",
    "hls4ml.report.read_vivado_report('cifar10-hls-test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
