{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a012a9a8",
   "metadata": {},
   "source": [
    "# Part 4: Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93caa31d",
   "metadata": {},
   "source": [
    "## Load Cifar10 dataset from tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aeb496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "#x_train = np.expand_dims(x_train, -1)\n",
    "#x_test = np.expand_dims(x_test, -1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a9d3d",
   "metadata": {},
   "source": [
    "### Let's print some information about the dataset\n",
    "Print the the dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74762a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e1ebbd",
   "metadata": {},
   "source": [
    "## Construct a model\n",
    "This time we're going to use QKeras layers.\n",
    "QKeras is \"Quantized Keras\" for deep heterogeneous quantization of ML models.\n",
    "\n",
    "https://github.com/google/qkeras\n",
    "\n",
    "It is maintained by Google and recently support for QKeras model is added to hls4ml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e1ffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from qkeras.qconvolutional import QConv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout,Flatten,InputLayer, MaxPooling2D, Activation\n",
    "\n",
    "model = Sequential()\n",
    "input_shape = (32, 32, 3)\n",
    "model.add(InputLayer(input_shape=input_shape))\n",
    "model.add(QConv2D(16, kernel_size=(3, 3),kernel_quantizer=quantized_bits(6,0,alpha=1),  bias_quantizer=quantized_bits(6,0,alpha=1)))\n",
    "model.add(QActivation(activation=quantized_relu(6)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(QConv2D(16, kernel_size=(3, 3),kernel_quantizer=quantized_bits(6,0,alpha=1),  bias_quantizer=quantized_bits(6,0,alpha=1)))\n",
    "model.add(QActivation(activation=quantized_relu(6)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(QConv2D(16, kernel_size=(3, 3),kernel_quantizer=quantized_bits(6,0,alpha=1),  bias_quantizer=quantized_bits(6,0,alpha=1)))\n",
    "model.add(QActivation(activation=quantized_relu(6)))\n",
    "model.add(Flatten())\n",
    "model.add(QDense(10,kernel_quantizer=quantized_bits(6,0,alpha=1),  bias_quantizer=quantized_bits(6,0,alpha=1)))\n",
    "model.add(Activation(activation='softmax'))\n",
    "\n",
    "model.build()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962dcbb8",
   "metadata": {},
   "source": [
    "## Train sparse\n",
    "Let's train with model sparsity again, since QKeras layers are prunable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb15285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.8, begin_step=0, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a68b397",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We'll use the same settings as the model for part 1: Adam optimizer with categorical crossentropy loss.\n",
    "The callbacks will decay the learning rate and save the model into a directory 'model_mnist_cnn4'\n",
    "The model isn't very complex, so this should just take a few minutes even on the CPU.\n",
    "If you've restarted the notebook kernel after training once, set `train = False` to load the trained model rather than training again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f66a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "train =True\n",
    "\n",
    "\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks = all_callbacks(stop_patience = 1000,\n",
    "                              lr_factor = 0.5,\n",
    "                              lr_patience = 10,\n",
    "                              lr_epsilon = 0.000001,\n",
    "                              lr_cooldown = 2,\n",
    "                              lr_minimum = 0.0000001,\n",
    "                              outputDir = 'model_cifar10_cnn4')\n",
    "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "    model.fit(x_train, y_train, batch_size=128,\n",
    "              epochs=100, validation_split=0.2, shuffle=True,\n",
    "              callbacks = callbacks.callbacks)\n",
    "    model = strip_pruning(model)\n",
    "    model.save('model_cifar10_cnn4/KERAS_check_best_model.h5')\n",
    "else:\n",
    "    from qkeras.utils import load_qmodel\n",
    "    model = load_qmodel('model_cifar10_cnn4/KERAS_check_best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb0d84",
   "metadata": {},
   "source": [
    "## Check performance\n",
    "How does this model which was trained using 6-bits, and 75% sparsity model compare against the original model? Let's report the accuracy and make a ROC curve. The quantized, pruned model is shown with solid lines, the unpruned model from part 1 is shown with dashed lines.\n",
    "\n",
    "\n",
    "We should also check that hls4ml can respect the choice to use 6-bits throughout the model, and match the accuracy. We'll generate a configuration from this Quantized model, and plot its performance as the dotted line.\n",
    "The generated configuration is printed out. You'll notice that it uses 7 bits for the type, but we specified 6!? That's just because QKeras doesn't count the sign-bit when we specify the number of bits, so the type that actually gets used needs 1 more.\n",
    "\n",
    "We also use the `OutputRoundingSaturationMode` optimizer pass of `hls4ml` to set the Activation layers to round, rather than truncate, the cast. This is important for getting good model accuracy when using small bit precision activations. And we'll set a different data type for the tables used in the Softmax, just for a bit of extra performance.\n",
    "\n",
    "\n",
    "**Make sure you've trained the model from part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b764db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hls4ml\n",
    "from hls4ml.converters.keras_to_hls import keras_to_hls\n",
    "import plotting\n",
    "import yaml\n",
    "\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "config['Backend']='VivadoAccelerator'\n",
    "config['OutputDir'] = 'cifar10-hls-test4'\n",
    "config['ProjectName'] = 'myproject_cifar10_cnn4'\n",
    "config['XilinxPart']= 'xczu7ev-ffvc1156-2-e'\n",
    "config['Board'] = 'zcu104'\n",
    "config['ClockPeriod'] = 5\n",
    "config['IOType'] = 'io_stream'\n",
    "config['HLSConfig']={}\n",
    "config['HLSConfig']['Model']={}\n",
    "config['HLSConfig']['Model']=config['Model']\n",
    "config['HLSConfig']['LayerName']=config['LayerName']\n",
    "\n",
    "del config['Model']\n",
    "del config['LayerName']\n",
    "config['AcceleratorConfig']={}\n",
    "config['AcceleratorConfig']['Interface'] = 'axi_stream'\n",
    "config['AcceleratorConfig']['Driver'] = 'python'\n",
    "config['AcceleratorConfig']['Precision']={}\n",
    "config['AcceleratorConfig']['Precision']['Input']= 'float'\n",
    "config['AcceleratorConfig']['Precision']['Output']= 'float'\n",
    "config['KerasModel'] = model\n",
    "config['HLSConfig']['LayerName']['q_conv2d_29']['ReuseFactor'] = 8\n",
    "config['HLSConfig']['LayerName']['q_conv2d_30']['ReuseFactor'] = 8\n",
    "config['HLSConfig']['LayerName']['q_conv2d_31']['ReuseFactor'] = 8\n",
    "config['HLSConfig']['LayerName']['q_dense_11']['ReuseFactor'] = 8\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = keras_to_hls(config)\n",
    "hls_model.compile()\n",
    "y_qkeras = model.predict(x_test)\n",
    "x_test = np.ascontiguousarray(x_test)\n",
    "y_hls = hls_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_ref = load_model('model_cifar10_cnn/KERAS_check_best_model.h5')\n",
    "y_ref = model_ref.predict(x_test)\n",
    "\n",
    "print(\"Accuracy baseline:  {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_ref, axis=1))))\n",
    "print(\"Accuracy pruned, quantized: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))\n",
    "print(\"Accuracy hls4ml: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee25da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cifar10_classes=['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(y_test, y_ref, cifar10_classes)\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.makeRoc(y_test, y_qkeras, cifar10_classes, linestyle='--')\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.makeRoc(y_test, y_hls,cifar10_classes, linestyle=':')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--'),\n",
    "         Line2D([0], [0], ls=':')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['baseline', 'pruned, quantized', 'hls4ml'],\n",
    "            loc='lower left', frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b174a2f",
   "metadata": {},
   "source": [
    "# Synthesize\n",
    "Now let's synthesize this quantized, pruned model.\n",
    "\n",
    "**The synthesis will take a while**\n",
    "\n",
    "While the C-Synthesis is running, we can monitor the progress looking at the log file by opening a terminal from the notebook home, and executing:\n",
    "\n",
    "`tail -f mnist-hls-test4/vivado_hls.log`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f155a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] = '/workspace/home/Xilinx/Vivado/2019.2/bin:' + os.environ['PATH']\n",
    "hls_model.build(csim=False,synth=True,export=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af97f6",
   "metadata": {},
   "source": [
    "## Check the reports\n",
    "Print out the reports generated by Vivado HLS. Pay attention to the Utilization Estimates' section in particular this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f69a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report(config['OutputDir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128da6a2",
   "metadata": {},
   "source": [
    "Print the report for the model trained in part 1. Now, compared to the model from part 1, this model has been trained with low-precision quantization, and 75% pruning. You should be able to see that we have saved a lot of resource compared to where we started in part 1. At the same time, referring to the ROC curve above, the model performance is pretty much identical even with this drastic compression!\n",
    "\n",
    "**Note you need to have trained and synthesized the model from part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b13853",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('cifar10-hls-test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821e8bf2",
   "metadata": {},
   "source": [
    "Print the report for the model trained in part 3. Both these models were trained with 75% sparsity, but the new model uses 6-bit precision as well. You can see how Vivado HLS has moved multiplication operations from DSPs into LUTs, reducing the \"critical\" resource usage.\n",
    "\n",
    "**Note you need to have trained and synthesized the model from part 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('cifar10-hls-test3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
