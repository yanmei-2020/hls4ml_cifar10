{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a012a9a8",
   "metadata": {},
   "source": [
    "# Part 4: Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93caa31d",
   "metadata": {},
   "source": [
    "## Load Cifar10 dataset from tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3aeb496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "#x_train = np.expand_dims(x_train, -1)\n",
    "#x_test = np.expand_dims(x_test, -1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a9d3d",
   "metadata": {},
   "source": [
    "### Let's print some information about the dataset\n",
    "Print the the dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74762a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3) (50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape,y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e1ebbd",
   "metadata": {},
   "source": [
    "## Construct a model\n",
    "This time we're going to use QKeras layers.\n",
    "QKeras is \"Quantized Keras\" for deep heterogeneous quantization of ML models.\n",
    "\n",
    "https://github.com/google/qkeras\n",
    "\n",
    "It is maintained by Google and recently support for QKeras model is added to hls4ml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80e1ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "q_conv2d_29 (QConv2D)        (None, 30, 30, 16)        448       \n",
      "_________________________________________________________________\n",
      "q_activation_28 (QActivation (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "q_conv2d_30 (QConv2D)        (None, 13, 13, 16)        2320      \n",
      "_________________________________________________________________\n",
      "q_activation_29 (QActivation (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "q_conv2d_31 (QConv2D)        (None, 4, 4, 16)          2320      \n",
      "_________________________________________________________________\n",
      "q_activation_30 (QActivation (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "q_dense_11 (QDense)          (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,658\n",
      "Trainable params: 7,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from qkeras.qconvolutional import QConv2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout,Flatten,InputLayer, MaxPooling2D, Activation\n",
    "\n",
    "model = Sequential()\n",
    "input_shape = (32, 32, 3)\n",
    "model.add(InputLayer(input_shape=input_shape))\n",
    "model.add(QConv2D(16, kernel_size=(3, 3),kernel_quantizer=quantized_bits(6,0,alpha=1),  bias_quantizer=quantized_bits(6,0,alpha=1)))\n",
    "model.add(QActivation(activation=quantized_relu(6)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(QConv2D(16, kernel_size=(3, 3),kernel_quantizer=quantized_bits(6,0,alpha=1),  bias_quantizer=quantized_bits(6,0,alpha=1)))\n",
    "model.add(QActivation(activation=quantized_relu(6)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(QConv2D(16, kernel_size=(3, 3),kernel_quantizer=quantized_bits(6,0,alpha=1),  bias_quantizer=quantized_bits(6,0,alpha=1)))\n",
    "model.add(QActivation(activation=quantized_relu(6)))\n",
    "model.add(Flatten())\n",
    "model.add(QDense(10,kernel_quantizer=quantized_bits(6,0,alpha=1),  bias_quantizer=quantized_bits(6,0,alpha=1)))\n",
    "model.add(Activation(activation='softmax'))\n",
    "\n",
    "model.build()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962dcbb8",
   "metadata": {},
   "source": [
    "## Train sparse\n",
    "Let's train with model sparsity again, since QKeras layers are prunable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dcb15285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.8, begin_step=0, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a68b397",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We'll use the same settings as the model for part 1: Adam optimizer with categorical crossentropy loss.\n",
    "The callbacks will decay the learning rate and save the model into a directory 'model_mnist_cnn4'\n",
    "The model isn't very complex, so this should just take a few minutes even on the CPU.\n",
    "If you've restarted the notebook kernel after training once, set `train = False` to load the trained model rather than training again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f66a031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 08:01:04.800490: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/313 [..............................] - ETA: 0s - loss: 2.5423 - accuracy: 0.1016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 08:01:09.472027: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/313 [..............................] - ETA: 49s - loss: 2.6118 - accuracy: 0.0859WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0279s vs `on_train_batch_end` time: 0.2875s). Check your callbacks.\n",
      " 10/313 [..............................] - ETA: 15s - loss: 2.5208 - accuracy: 0.0969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-28 08:01:09.685286: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: model_cifar10_cnn4/logs/train/plugins/profile/2021_11_28_08_01_09\n",
      "2021-11-28 08:01:09.698349: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for trace.json.gz to model_cifar10_cnn4/logs/train/plugins/profile/2021_11_28_08_01_09/ECE-util1.trace.json.gz\n",
      "2021-11-28 08:01:09.716683: I tensorflow/core/profiler/rpc/client/save_profile.cc:176] Creating directory: model_cifar10_cnn4/logs/train/plugins/profile/2021_11_28_08_01_09\n",
      "2021-11-28 08:01:09.724079: I tensorflow/core/profiler/rpc/client/save_profile.cc:182] Dumped gzipped tool data for memory_profile.json.gz to model_cifar10_cnn4/logs/train/plugins/profile/2021_11_28_08_01_09/ECE-util1.memory_profile.json.gz\n",
      "2021-11-28 08:01:09.783572: I tensorflow/python/profiler/internal/profiler_wrapper.cc:111] Creating directory: model_cifar10_cnn4/logs/train/plugins/profile/2021_11_28_08_01_09Dumped tool data for xplane.pb to model_cifar10_cnn4/logs/train/plugins/profile/2021_11_28_08_01_09/ECE-util1.xplane.pb\n",
      "Dumped tool data for overview_page.pb to model_cifar10_cnn4/logs/train/plugins/profile/2021_11_28_08_01_09/ECE-util1.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to model_cifar10_cnn4/logs/train/plugins/profile/2021_11_28_08_01_09/ECE-util1.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to model_cifar10_cnn4/logs/train/plugins/profile/2021_11_28_08_01_09/ECE-util1.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to model_cifar10_cnn4/logs/train/plugins/profile/2021_11_28_08_01_09/ECE-util1.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/313 [============================>.] - ETA: 0s - loss: 2.3239 - accuracy: 0.0932\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.29608, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.29608, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00001: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00001: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 2.3238 - accuracy: 0.0933 - val_loss: 2.2961 - val_accuracy: 0.1053\n",
      "Epoch 2/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 2.2873 - accuracy: 0.1238\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.29608 to 2.27424, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.29608 to 2.27424, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00002: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00002: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 2.2872 - accuracy: 0.1239 - val_loss: 2.2742 - val_accuracy: 0.1429\n",
      "Epoch 3/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 2.2563 - accuracy: 0.1666\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.27424 to 2.23494, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.27424 to 2.23494, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00003: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00003: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 2.2562 - accuracy: 0.1664 - val_loss: 2.2349 - val_accuracy: 0.1933\n",
      "Epoch 4/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 2.2082 - accuracy: 0.2133\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.23494 to 2.18093, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.23494 to 2.18093, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00004: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00004: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 2.2081 - accuracy: 0.2132 - val_loss: 2.1809 - val_accuracy: 0.2296\n",
      "Epoch 5/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 2.1491 - accuracy: 0.2375\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.18093 to 2.11254, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.18093 to 2.11254, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00005: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00005: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 2.1490 - accuracy: 0.2374 - val_loss: 2.1125 - val_accuracy: 0.2456\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 2.0823 - accuracy: 0.2553\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.11254 to 2.05011, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.11254 to 2.05011, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00006: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00006: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 2.0823 - accuracy: 0.2553 - val_loss: 2.0501 - val_accuracy: 0.2567\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 2.0274 - accuracy: 0.2713\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.05011 to 2.00582, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.05011 to 2.00582, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00007: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00007: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 2.0274 - accuracy: 0.2713 - val_loss: 2.0058 - val_accuracy: 0.2677\n",
      "Epoch 8/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.9834 - accuracy: 0.2826\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.00582 to 1.96681, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.00582 to 1.96681, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00008: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00008: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.9834 - accuracy: 0.2828 - val_loss: 1.9668 - val_accuracy: 0.2868\n",
      "Epoch 9/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.9469 - accuracy: 0.2985\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.96681 to 1.93030, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.96681 to 1.93030, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00009: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00009: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.9469 - accuracy: 0.2985 - val_loss: 1.9303 - val_accuracy: 0.3012\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.9126 - accuracy: 0.3123\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.93030 to 1.90135, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.93030 to 1.90135, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00010: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00010: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00010: saving model to model_cifar10_cnn4/KERAS_check_model_epoch10.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.9126 - accuracy: 0.3123 - val_loss: 1.9013 - val_accuracy: 0.3143\n",
      "Epoch 11/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.8839 - accuracy: 0.3224\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.90135 to 1.87303, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.90135 to 1.87303, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00011: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00011: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.8840 - accuracy: 0.3224 - val_loss: 1.8730 - val_accuracy: 0.3201\n",
      "Epoch 12/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.8604 - accuracy: 0.3296\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.87303 to 1.85236, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.87303 to 1.85236, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00012: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00012: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.8603 - accuracy: 0.3297 - val_loss: 1.8524 - val_accuracy: 0.3298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.8385 - accuracy: 0.3373\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.85236 to 1.82984, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.85236 to 1.82984, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00013: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00013: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.8386 - accuracy: 0.3374 - val_loss: 1.8298 - val_accuracy: 0.3355\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.8183 - accuracy: 0.3449\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.82984 to 1.81436, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.82984 to 1.81436, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00014: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00014: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.8183 - accuracy: 0.3449 - val_loss: 1.8144 - val_accuracy: 0.3419\n",
      "Epoch 15/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.8038 - accuracy: 0.3505\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.81436 to 1.79815, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.81436 to 1.79815, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00015: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00015: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.8037 - accuracy: 0.3506 - val_loss: 1.7981 - val_accuracy: 0.3458\n",
      "Epoch 16/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.7877 - accuracy: 0.3546\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.79815 to 1.78413, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.79815 to 1.78413, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00016: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00016: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.7878 - accuracy: 0.3544 - val_loss: 1.7841 - val_accuracy: 0.3529\n",
      "Epoch 17/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.7755 - accuracy: 0.3589\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.78413 to 1.77427, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.78413 to 1.77427, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00017: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00017: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.7752 - accuracy: 0.3590 - val_loss: 1.7743 - val_accuracy: 0.3586\n",
      "Epoch 18/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.7635 - accuracy: 0.3636\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.77427 to 1.76188, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.77427 to 1.76188, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00018: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00018: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.7634 - accuracy: 0.3636 - val_loss: 1.7619 - val_accuracy: 0.3574\n",
      "Epoch 19/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.7539 - accuracy: 0.3662\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.76188 to 1.75360, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.76188 to 1.75360, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00019: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00019: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.7536 - accuracy: 0.3664 - val_loss: 1.7536 - val_accuracy: 0.3613\n",
      "Epoch 20/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.7438 - accuracy: 0.3698\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.75360 to 1.75066, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.75360 to 1.75066, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00020: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00020: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00020: saving model to model_cifar10_cnn4/KERAS_check_model_epoch20.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.7442 - accuracy: 0.3696 - val_loss: 1.7507 - val_accuracy: 0.3621\n",
      "Epoch 21/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.7346 - accuracy: 0.3716\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.75066 to 1.73572, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.75066 to 1.73572, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00021: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00021: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.7343 - accuracy: 0.3717 - val_loss: 1.7357 - val_accuracy: 0.3684\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.7257 - accuracy: 0.3740\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.73572 to 1.72579, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.73572 to 1.72579, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00022: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00022: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.7257 - accuracy: 0.3740 - val_loss: 1.7258 - val_accuracy: 0.3702\n",
      "Epoch 23/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.7171 - accuracy: 0.3783\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.72579 to 1.72125, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.72579 to 1.72125, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00023: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00023: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.7169 - accuracy: 0.3784 - val_loss: 1.7212 - val_accuracy: 0.3732\n",
      "Epoch 24/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.7086 - accuracy: 0.3809\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.72125 to 1.71049, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.72125 to 1.71049, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00024: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00024: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.7084 - accuracy: 0.3810 - val_loss: 1.7105 - val_accuracy: 0.3769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.7001 - accuracy: 0.3839\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.71049 to 1.70277, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.71049 to 1.70277, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00025: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00025: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.7000 - accuracy: 0.3838 - val_loss: 1.7028 - val_accuracy: 0.3799\n",
      "Epoch 26/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.6928 - accuracy: 0.3851\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.70277 to 1.69540, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.70277 to 1.69540, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00026: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00026: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6927 - accuracy: 0.3851 - val_loss: 1.6954 - val_accuracy: 0.3835\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.6862 - accuracy: 0.3880\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.69540 to 1.69074, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.69540 to 1.69074, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00027: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00027: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6862 - accuracy: 0.3880 - val_loss: 1.6907 - val_accuracy: 0.3845\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.6791 - accuracy: 0.3905\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.69074 to 1.68206, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.69074 to 1.68206, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00028: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00028: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6791 - accuracy: 0.3905 - val_loss: 1.6821 - val_accuracy: 0.3866\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.6722 - accuracy: 0.3925\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.68206 to 1.67762, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.68206 to 1.67762, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00029: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00029: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6722 - accuracy: 0.3925 - val_loss: 1.6776 - val_accuracy: 0.3898\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.6655 - accuracy: 0.3957\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.67762 to 1.67251, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.67762 to 1.67251, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00030: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00030: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00030: saving model to model_cifar10_cnn4/KERAS_check_model_epoch30.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6655 - accuracy: 0.3957 - val_loss: 1.6725 - val_accuracy: 0.3938\n",
      "Epoch 31/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.6604 - accuracy: 0.3967\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.67251 to 1.66557, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.67251 to 1.66557, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00031: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00031: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6606 - accuracy: 0.3966 - val_loss: 1.6656 - val_accuracy: 0.3978\n",
      "Epoch 32/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.6536 - accuracy: 0.3997\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.66557 to 1.66014, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.66557 to 1.66014, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00032: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00032: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6539 - accuracy: 0.3995 - val_loss: 1.6601 - val_accuracy: 0.4015\n",
      "Epoch 33/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.6489 - accuracy: 0.4002\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.66014 to 1.65403, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.66014 to 1.65403, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00033: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00033: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6484 - accuracy: 0.4000 - val_loss: 1.6540 - val_accuracy: 0.4034\n",
      "Epoch 34/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.6426 - accuracy: 0.4037\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.65403 to 1.64939, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.65403 to 1.64939, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00034: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00034: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6428 - accuracy: 0.4033 - val_loss: 1.6494 - val_accuracy: 0.4028\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.6370 - accuracy: 0.4046\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.64939\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 1.64939\n",
      "\n",
      "Epoch 00035: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00035: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6370 - accuracy: 0.4046 - val_loss: 1.6543 - val_accuracy: 0.4038\n",
      "Epoch 36/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.6342 - accuracy: 0.4068\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.64939 to 1.63819, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.64939 to 1.63819, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00036: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00036: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6344 - accuracy: 0.4068 - val_loss: 1.6382 - val_accuracy: 0.4067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.6278 - accuracy: 0.4079\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.63819 to 1.63537, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.63819 to 1.63537, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00037: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00037: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6282 - accuracy: 0.4078 - val_loss: 1.6354 - val_accuracy: 0.4102\n",
      "Epoch 38/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.6255 - accuracy: 0.4110\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.63537\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.63537\n",
      "\n",
      "Epoch 00038: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00038: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6255 - accuracy: 0.4110 - val_loss: 1.6385 - val_accuracy: 0.4093\n",
      "Epoch 39/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.6217 - accuracy: 0.4110\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.63537 to 1.62634, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.63537 to 1.62634, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00039: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00039: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6215 - accuracy: 0.4110 - val_loss: 1.6263 - val_accuracy: 0.4117\n",
      "Epoch 40/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.6163 - accuracy: 0.4115\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.62634 to 1.62470, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.62634 to 1.62470, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00040: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00040: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00040: saving model to model_cifar10_cnn4/KERAS_check_model_epoch40.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6164 - accuracy: 0.4115 - val_loss: 1.6247 - val_accuracy: 0.4144\n",
      "Epoch 41/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.6106 - accuracy: 0.4149\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.62470 to 1.61760, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.62470 to 1.61760, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00041: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00041: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6104 - accuracy: 0.4148 - val_loss: 1.6176 - val_accuracy: 0.4174\n",
      "Epoch 42/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.6060 - accuracy: 0.4152\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.61760 to 1.61195, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.61760 to 1.61195, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00042: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00042: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6052 - accuracy: 0.4156 - val_loss: 1.6120 - val_accuracy: 0.4217\n",
      "Epoch 43/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.6003 - accuracy: 0.4184\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.61195 to 1.60965, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.61195 to 1.60965, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00043: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00043: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.6008 - accuracy: 0.4182 - val_loss: 1.6097 - val_accuracy: 0.4220\n",
      "Epoch 44/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5972 - accuracy: 0.4209\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.60965 to 1.60899, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.60965 to 1.60899, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00044: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00044: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5970 - accuracy: 0.4210 - val_loss: 1.6090 - val_accuracy: 0.4179\n",
      "Epoch 45/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.5937 - accuracy: 0.4209\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.60899 to 1.60349, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.60899 to 1.60349, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00045: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00045: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5935 - accuracy: 0.4209 - val_loss: 1.6035 - val_accuracy: 0.4221\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.5903 - accuracy: 0.4225\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.60349\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.60349\n",
      "\n",
      "Epoch 00046: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00046: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5903 - accuracy: 0.4225 - val_loss: 1.6141 - val_accuracy: 0.4215\n",
      "Epoch 47/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.5870 - accuracy: 0.4247\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.60349 to 1.59605, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.60349 to 1.59605, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00047: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00047: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5869 - accuracy: 0.4247 - val_loss: 1.5960 - val_accuracy: 0.4219\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.5830 - accuracy: 0.4264\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.59605 to 1.59188, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.59605 to 1.59188, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00048: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00048: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5830 - accuracy: 0.4264 - val_loss: 1.5919 - val_accuracy: 0.4223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.5785 - accuracy: 0.4279\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.59188 to 1.59178, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.59188 to 1.59178, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00049: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00049: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5787 - accuracy: 0.4279 - val_loss: 1.5918 - val_accuracy: 0.4275\n",
      "Epoch 50/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.5762 - accuracy: 0.4298\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.59178 to 1.58509, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.59178 to 1.58509, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00050: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00050: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00050: saving model to model_cifar10_cnn4/KERAS_check_model_epoch50.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.5764 - accuracy: 0.4299 - val_loss: 1.5851 - val_accuracy: 0.4266\n",
      "Epoch 51/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.5721 - accuracy: 0.4311\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.58509\n",
      "\n",
      "Epoch 00051: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00051: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5723 - accuracy: 0.4309 - val_loss: 1.5855 - val_accuracy: 0.4236\n",
      "Epoch 52/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.5692 - accuracy: 0.4316\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.58509 to 1.57916, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.58509 to 1.57916, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00052: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00052: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5689 - accuracy: 0.4318 - val_loss: 1.5792 - val_accuracy: 0.4275\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.5647 - accuracy: 0.4340\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.57916 to 1.57459, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.57916 to 1.57459, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00053: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00053: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5647 - accuracy: 0.4340 - val_loss: 1.5746 - val_accuracy: 0.4325\n",
      "Epoch 54/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5611 - accuracy: 0.4348\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.57459 to 1.57106, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.57459 to 1.57106, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00054: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00054: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5608 - accuracy: 0.4348 - val_loss: 1.5711 - val_accuracy: 0.4305\n",
      "Epoch 55/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5580 - accuracy: 0.4367\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.57106\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.57106\n",
      "\n",
      "Epoch 00055: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00055: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5580 - accuracy: 0.4367 - val_loss: 1.5713 - val_accuracy: 0.4296\n",
      "Epoch 56/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.5548 - accuracy: 0.4386\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.57106 to 1.56794, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.57106 to 1.56794, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00056: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00056: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5544 - accuracy: 0.4388 - val_loss: 1.5679 - val_accuracy: 0.4328\n",
      "Epoch 57/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5512 - accuracy: 0.4382\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.56794\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.56794\n",
      "\n",
      "Epoch 00057: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00057: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5515 - accuracy: 0.4381 - val_loss: 1.5701 - val_accuracy: 0.4305\n",
      "Epoch 58/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.5502 - accuracy: 0.4388\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.56794 to 1.55860, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.56794 to 1.55860, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00058: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00058: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5502 - accuracy: 0.4388 - val_loss: 1.5586 - val_accuracy: 0.4381\n",
      "Epoch 59/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5448 - accuracy: 0.4427\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.55860\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.55860\n",
      "\n",
      "Epoch 00059: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00059: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5441 - accuracy: 0.4429 - val_loss: 1.5587 - val_accuracy: 0.4360\n",
      "Epoch 60/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5420 - accuracy: 0.4420\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00060: val_loss improved from 1.55860 to 1.55801, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00060: val_loss improved from 1.55860 to 1.55801, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00060: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00060: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00060: saving model to model_cifar10_cnn4/KERAS_check_model_epoch60.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.5416 - accuracy: 0.4419 - val_loss: 1.5580 - val_accuracy: 0.4349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.5394 - accuracy: 0.4436\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.55801 to 1.55166, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.55801 to 1.55166, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00061: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00061: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5394 - accuracy: 0.4436 - val_loss: 1.5517 - val_accuracy: 0.4386\n",
      "Epoch 62/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.5365 - accuracy: 0.4452\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.55166 to 1.54644, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.55166 to 1.54644, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00062: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00062: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5363 - accuracy: 0.4455 - val_loss: 1.5464 - val_accuracy: 0.4391\n",
      "Epoch 63/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.5331 - accuracy: 0.4453\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.54644 to 1.54384, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.54644 to 1.54384, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00063: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00063: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5330 - accuracy: 0.4453 - val_loss: 1.5438 - val_accuracy: 0.4414\n",
      "Epoch 64/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.5314 - accuracy: 0.4460\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.54384 to 1.54099, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.54384 to 1.54099, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00064: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00064: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5313 - accuracy: 0.4459 - val_loss: 1.5410 - val_accuracy: 0.4433\n",
      "Epoch 65/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5271 - accuracy: 0.4484\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.54099\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.54099\n",
      "\n",
      "Epoch 00065: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00065: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5268 - accuracy: 0.4485 - val_loss: 1.5515 - val_accuracy: 0.4398\n",
      "Epoch 66/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5249 - accuracy: 0.4481\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.54099 to 1.53498, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.54099 to 1.53498, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00066: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00066: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5252 - accuracy: 0.4480 - val_loss: 1.5350 - val_accuracy: 0.4444\n",
      "Epoch 67/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5240 - accuracy: 0.4481\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.53498\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.53498\n",
      "\n",
      "Epoch 00067: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00067: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5235 - accuracy: 0.4485 - val_loss: 1.5351 - val_accuracy: 0.4463\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.5181 - accuracy: 0.4509\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.53498\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.53498\n",
      "\n",
      "Epoch 00068: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00068: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5181 - accuracy: 0.4509 - val_loss: 1.5354 - val_accuracy: 0.4430\n",
      "Epoch 69/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.5163 - accuracy: 0.4537\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00069: val_loss improved from 1.53498 to 1.53116, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00069: val_loss improved from 1.53498 to 1.53116, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00069: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00069: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5168 - accuracy: 0.4537 - val_loss: 1.5312 - val_accuracy: 0.4462\n",
      "Epoch 70/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5171 - accuracy: 0.4550\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.53116\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.53116\n",
      "\n",
      "Epoch 00070: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00070: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00070: saving model to model_cifar10_cnn4/KERAS_check_model_epoch70.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5168 - accuracy: 0.4548 - val_loss: 1.5401 - val_accuracy: 0.4402\n",
      "Epoch 71/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5130 - accuracy: 0.4517\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.53116 to 1.52204, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00071: val_loss improved from 1.53116 to 1.52204, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00071: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00071: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5132 - accuracy: 0.4518 - val_loss: 1.5220 - val_accuracy: 0.4465\n",
      "Epoch 72/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.5104 - accuracy: 0.4553\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.52204 to 1.52104, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00072: val_loss improved from 1.52204 to 1.52104, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00072: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00072: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5106 - accuracy: 0.4554 - val_loss: 1.5210 - val_accuracy: 0.4497\n",
      "Epoch 73/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.5065 - accuracy: 0.4566\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00073: val_loss improved from 1.52104 to 1.51878, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00073: val_loss improved from 1.52104 to 1.51878, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00073: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00073: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5067 - accuracy: 0.4562 - val_loss: 1.5188 - val_accuracy: 0.4488\n",
      "Epoch 74/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.5058 - accuracy: 0.4574\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.51878\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.51878\n",
      "\n",
      "Epoch 00074: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00074: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5053 - accuracy: 0.4575 - val_loss: 1.5264 - val_accuracy: 0.4470\n",
      "Epoch 75/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.5047 - accuracy: 0.4584\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.51878\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.51878\n",
      "\n",
      "Epoch 00075: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00075: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.5045 - accuracy: 0.4584 - val_loss: 1.5231 - val_accuracy: 0.4487\n",
      "Epoch 76/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.4991 - accuracy: 0.4617\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.51878 to 1.51000, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00076: val_loss improved from 1.51878 to 1.51000, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00076: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00076: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4992 - accuracy: 0.4616 - val_loss: 1.5100 - val_accuracy: 0.4542\n",
      "Epoch 77/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.4960 - accuracy: 0.4609\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00077: val_loss improved from 1.51000 to 1.50789, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00077: val_loss improved from 1.51000 to 1.50789, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00077: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00077: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4960 - accuracy: 0.4609 - val_loss: 1.5079 - val_accuracy: 0.4525\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.4942 - accuracy: 0.4616\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00078: val_loss improved from 1.50789 to 1.50670, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00078: val_loss improved from 1.50789 to 1.50670, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00078: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00078: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4942 - accuracy: 0.4616 - val_loss: 1.5067 - val_accuracy: 0.4559\n",
      "Epoch 79/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.4914 - accuracy: 0.4643\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.50670\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.50670\n",
      "\n",
      "Epoch 00079: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00079: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4913 - accuracy: 0.4640 - val_loss: 1.5102 - val_accuracy: 0.4523\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.4900 - accuracy: 0.4645\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.50670\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.50670\n",
      "\n",
      "Epoch 00080: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00080: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00080: saving model to model_cifar10_cnn4/KERAS_check_model_epoch80.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4900 - accuracy: 0.4645 - val_loss: 1.5077 - val_accuracy: 0.4537\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.4882 - accuracy: 0.4656\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.50670 to 1.50057, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.50670 to 1.50057, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00081: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00081: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4882 - accuracy: 0.4656 - val_loss: 1.5006 - val_accuracy: 0.4555\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.4840 - accuracy: 0.4665\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00082: val_loss improved from 1.50057 to 1.49617, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00082: val_loss improved from 1.50057 to 1.49617, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00082: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00082: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4840 - accuracy: 0.4665 - val_loss: 1.4962 - val_accuracy: 0.4589\n",
      "Epoch 83/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.4836 - accuracy: 0.4667\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.49617 to 1.49577, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00083: val_loss improved from 1.49617 to 1.49577, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00083: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00083: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4831 - accuracy: 0.4669 - val_loss: 1.4958 - val_accuracy: 0.4566\n",
      "Epoch 84/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.4781 - accuracy: 0.4701\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.49577 to 1.49534, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00084: val_loss improved from 1.49577 to 1.49534, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00084: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00084: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4783 - accuracy: 0.4699 - val_loss: 1.4953 - val_accuracy: 0.4554\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/313 [============================>.] - ETA: 0s - loss: 1.4776 - accuracy: 0.4686\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.49534\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.49534\n",
      "\n",
      "Epoch 00085: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00085: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4774 - accuracy: 0.4686 - val_loss: 1.5007 - val_accuracy: 0.4561\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.4759 - accuracy: 0.4687\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00086: val_loss improved from 1.49534 to 1.48919, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00086: val_loss improved from 1.49534 to 1.48919, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00086: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00086: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4759 - accuracy: 0.4687 - val_loss: 1.4892 - val_accuracy: 0.4605\n",
      "Epoch 87/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.4735 - accuracy: 0.4696\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00087: val_loss improved from 1.48919 to 1.48916, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00087: val_loss improved from 1.48919 to 1.48916, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00087: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00087: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4739 - accuracy: 0.4693 - val_loss: 1.4892 - val_accuracy: 0.4591\n",
      "Epoch 88/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.4720 - accuracy: 0.4705\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00088: val_loss improved from 1.48916 to 1.48459, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00088: val_loss improved from 1.48916 to 1.48459, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00088: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00088: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4713 - accuracy: 0.4710 - val_loss: 1.4846 - val_accuracy: 0.4642\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.4687 - accuracy: 0.4715\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00089: val_loss improved from 1.48459 to 1.48278, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00089: val_loss improved from 1.48459 to 1.48278, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00089: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00089: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4687 - accuracy: 0.4715 - val_loss: 1.4828 - val_accuracy: 0.4570\n",
      "Epoch 90/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.4678 - accuracy: 0.4735\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00090: val_loss improved from 1.48278 to 1.48160, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00090: val_loss improved from 1.48278 to 1.48160, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00090: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00090: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00090: saving model to model_cifar10_cnn4/KERAS_check_model_epoch90.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4676 - accuracy: 0.4737 - val_loss: 1.4816 - val_accuracy: 0.4636\n",
      "Epoch 91/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.4658 - accuracy: 0.4730\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00091: val_loss improved from 1.48160 to 1.47918, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00091: val_loss improved from 1.48160 to 1.47918, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00091: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00091: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4656 - accuracy: 0.4732 - val_loss: 1.4792 - val_accuracy: 0.4623\n",
      "Epoch 92/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.4645 - accuracy: 0.4729\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00092: val_loss improved from 1.47918 to 1.47640, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00092: val_loss improved from 1.47918 to 1.47640, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00092: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00092: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4647 - accuracy: 0.4729 - val_loss: 1.4764 - val_accuracy: 0.4650\n",
      "Epoch 93/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.4613 - accuracy: 0.4745\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.47640 to 1.47528, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00093: val_loss improved from 1.47640 to 1.47528, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00093: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00093: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4611 - accuracy: 0.4749 - val_loss: 1.4753 - val_accuracy: 0.4630\n",
      "Epoch 94/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.4582 - accuracy: 0.4757\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00094: val_loss improved from 1.47528 to 1.47446, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00094: val_loss improved from 1.47528 to 1.47446, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00094: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00094: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4580 - accuracy: 0.4758 - val_loss: 1.4745 - val_accuracy: 0.4660\n",
      "Epoch 95/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.4567 - accuracy: 0.4766\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00095: val_loss improved from 1.47446 to 1.47332, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00095: val_loss improved from 1.47446 to 1.47332, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00095: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00095: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4566 - accuracy: 0.4766 - val_loss: 1.4733 - val_accuracy: 0.4661\n",
      "Epoch 96/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.4549 - accuracy: 0.4761\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.47332 to 1.47012, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00096: val_loss improved from 1.47332 to 1.47012, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00096: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00096: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4545 - accuracy: 0.4765 - val_loss: 1.4701 - val_accuracy: 0.4660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "313/313 [==============================] - ETA: 0s - loss: 1.4528 - accuracy: 0.4782\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.47012\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.47012\n",
      "\n",
      "Epoch 00097: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00097: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4528 - accuracy: 0.4782 - val_loss: 1.4757 - val_accuracy: 0.4678\n",
      "Epoch 98/100\n",
      "312/313 [============================>.] - ETA: 0s - loss: 1.4503 - accuracy: 0.4771\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.47012\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.47012\n",
      "\n",
      "Epoch 00098: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00098: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4505 - accuracy: 0.4771 - val_loss: 1.4707 - val_accuracy: 0.4672\n",
      "Epoch 99/100\n",
      "311/313 [============================>.] - ETA: 0s - loss: 1.4510 - accuracy: 0.4791\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00099: val_loss improved from 1.47012 to 1.47009, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00099: val_loss improved from 1.47012 to 1.47009, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00099: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00099: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4505 - accuracy: 0.4792 - val_loss: 1.4701 - val_accuracy: 0.4658\n",
      "Epoch 100/100\n",
      "310/313 [============================>.] - ETA: 0s - loss: 1.4496 - accuracy: 0.4793\n",
      "***callbacks***\n",
      "saving losses to model_cifar10_cnn4/losses.log\n",
      "\n",
      "Epoch 00100: val_loss improved from 1.47009 to 1.46675, saving model to model_cifar10_cnn4/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00100: val_loss improved from 1.47009 to 1.46675, saving model to model_cifar10_cnn4/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00100: saving model to model_cifar10_cnn4/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00100: saving model to model_cifar10_cnn4/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00100: saving model to model_cifar10_cnn4/KERAS_check_model_epoch100.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 1.4492 - accuracy: 0.4795 - val_loss: 1.4667 - val_accuracy: 0.4665\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "train =True\n",
    "\n",
    "\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks = all_callbacks(stop_patience = 1000,\n",
    "                              lr_factor = 0.5,\n",
    "                              lr_patience = 10,\n",
    "                              lr_epsilon = 0.000001,\n",
    "                              lr_cooldown = 2,\n",
    "                              lr_minimum = 0.0000001,\n",
    "                              outputDir = 'model_cifar10_cnn4')\n",
    "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "    model.fit(x_train, y_train, batch_size=128,\n",
    "              epochs=100, validation_split=0.2, shuffle=True,\n",
    "              callbacks = callbacks.callbacks)\n",
    "    model = strip_pruning(model)\n",
    "    model.save('model_cifar10_cnn4/KERAS_check_best_model.h5')\n",
    "else:\n",
    "    from qkeras.utils import load_qmodel\n",
    "    model = load_qmodel('model_cifar10_cnn4/KERAS_check_best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb0d84",
   "metadata": {},
   "source": [
    "## Check performance\n",
    "How does this model which was trained using 6-bits, and 75% sparsity model compare against the original model? Let's report the accuracy and make a ROC curve. The quantized, pruned model is shown with solid lines, the unpruned model from part 1 is shown with dashed lines.\n",
    "\n",
    "\n",
    "We should also check that hls4ml can respect the choice to use 6-bits throughout the model, and match the accuracy. We'll generate a configuration from this Quantized model, and plot its performance as the dotted line.\n",
    "The generated configuration is printed out. You'll notice that it uses 7 bits for the type, but we specified 6!? That's just because QKeras doesn't count the sign-bit when we specify the number of bits, so the type that actually gets used needs 1 more.\n",
    "\n",
    "We also use the `OutputRoundingSaturationMode` optimizer pass of `hls4ml` to set the Activation layers to round, rather than truncate, the cast. This is important for getting good model accuracy when using small bit precision activations. And we'll set a different data type for the tables used in the Softmax, just for a bit of extra performance.\n",
    "\n",
    "\n",
    "**Make sure you've trained the model from part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b764db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: input_11, layer type: Input\n",
      "Layer name: q_conv2d_29, layer type: QConv2D\n",
      "Layer name: q_activation_28, layer type: QActivation\n",
      "Layer name: max_pooling2d_20, layer type: MaxPooling2D\n",
      "Layer name: q_conv2d_30, layer type: QConv2D\n",
      "Layer name: q_activation_29, layer type: QActivation\n",
      "Layer name: max_pooling2d_21, layer type: MaxPooling2D\n",
      "Layer name: q_conv2d_31, layer type: QConv2D\n",
      "Layer name: q_activation_30, layer type: QActivation\n",
      "Layer name: q_dense_11, layer type: QDense\n",
      "Layer name: activation_10, layer type: Activation\n",
      "-----------------------------------\n",
      "Configuration\n",
      "Backend:             VivadoAccelerator\n",
      "OutputDir:           cifar10-hls-test4\n",
      "ProjectName:         myproject_cifar10_cnn4\n",
      "XilinxPart:          xczu7ev-ffvc1156-2-e\n",
      "Board:               zcu104\n",
      "ClockPeriod:         5\n",
      "IOType:              io_stream\n",
      "HLSConfig\n",
      "  Model\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  LayerName\n",
      "    input_11\n",
      "      Precision\n",
      "        result:      ap_fixed<16,6>\n",
      "    q_conv2d_29\n",
      "      Precision\n",
      "        weight:      ap_fixed<6,1>\n",
      "        bias:        ap_fixed<6,1>\n",
      "      ReuseFactor:   8\n",
      "    q_activation_28\n",
      "      Precision\n",
      "        result:      ap_fixed<6,1>\n",
      "      ReuseFactor:   1\n",
      "    max_pooling2d_20\n",
      "      Precision:     ap_fixed<16,6>\n",
      "    q_conv2d_30\n",
      "      Precision\n",
      "        weight:      ap_fixed<6,1>\n",
      "        bias:        ap_fixed<6,1>\n",
      "      ReuseFactor:   8\n",
      "    q_activation_29\n",
      "      Precision\n",
      "        result:      ap_fixed<6,1>\n",
      "      ReuseFactor:   1\n",
      "    max_pooling2d_21\n",
      "      Precision:     ap_fixed<16,6>\n",
      "    q_conv2d_31\n",
      "      Precision\n",
      "        weight:      ap_fixed<6,1>\n",
      "        bias:        ap_fixed<6,1>\n",
      "      ReuseFactor:   8\n",
      "    q_activation_30\n",
      "      Precision\n",
      "        result:      ap_fixed<6,1>\n",
      "      ReuseFactor:   1\n",
      "    q_dense_11\n",
      "      Precision\n",
      "        weight:      ap_fixed<6,1>\n",
      "        bias:        ap_fixed<6,1>\n",
      "      ReuseFactor:   8\n",
      "    activation_10\n",
      "      Precision:     ap_fixed<16,6>\n",
      "      ReuseFactor:   1\n",
      "      table_size:    1024\n",
      "      exp_table_t:   ap_fixed<18,8,AP_RND,AP_SAT>\n",
      "      inv_table_t:   ap_fixed<18,8,AP_RND,AP_SAT>\n",
      "AcceleratorConfig\n",
      "  Interface:         axi_stream\n",
      "  Driver:            python\n",
      "  Precision\n",
      "    Input:           float\n",
      "    Output:          float\n",
      "KerasModel:          <tensorflow.python.keras.engine.sequential.Sequential object at 0x7ff4833f9910>\n",
      "-----------------------------------\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: input_11, layer type: InputLayer, input shapes: [[None, 32, 32, 3]], output shape: [None, 32, 32, 3]\n",
      "Layer name: q_conv2d_29, layer type: QConv2D, input shapes: [[None, 32, 32, 3]], output shape: [None, 30, 30, 16]\n",
      "Layer name: q_activation_28, layer type: Activation, input shapes: [[None, 30, 30, 16]], output shape: [None, 30, 30, 16]\n",
      "Layer name: max_pooling2d_20, layer type: MaxPooling2D, input shapes: [[None, 30, 30, 16]], output shape: [None, 15, 15, 16]\n",
      "Layer name: q_conv2d_30, layer type: QConv2D, input shapes: [[None, 15, 15, 16]], output shape: [None, 13, 13, 16]\n",
      "Layer name: q_activation_29, layer type: Activation, input shapes: [[None, 13, 13, 16]], output shape: [None, 13, 13, 16]\n",
      "Layer name: max_pooling2d_21, layer type: MaxPooling2D, input shapes: [[None, 13, 13, 16]], output shape: [None, 6, 6, 16]\n",
      "Layer name: q_conv2d_31, layer type: QConv2D, input shapes: [[None, 6, 6, 16]], output shape: [None, 4, 4, 16]\n",
      "Layer name: q_activation_30, layer type: Activation, input shapes: [[None, 4, 4, 16]], output shape: [None, 4, 4, 16]\n",
      "Layer name: flatten_10, layer type: Reshape, input shapes: [[None, 4, 4, 16]], output shape: [None, 256]\n",
      "Layer name: q_dense_11, layer type: QDense, input shapes: [[None, 256]], output shape: [None, 10]\n",
      "Layer name: activation_10, layer type: Softmax, input shapes: [[None, 10]], output shape: [None, 10]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "from hls4ml.converters.keras_to_hls import keras_to_hls\n",
    "import plotting\n",
    "import yaml\n",
    "\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "config['Backend']='VivadoAccelerator'\n",
    "config['OutputDir'] = 'cifar10-hls-test4'\n",
    "config['ProjectName'] = 'myproject_cifar10_cnn4'\n",
    "config['XilinxPart']= 'xczu7ev-ffvc1156-2-e'\n",
    "config['Board'] = 'zcu104'\n",
    "config['ClockPeriod'] = 5\n",
    "config['IOType'] = 'io_stream'\n",
    "config['HLSConfig']={}\n",
    "config['HLSConfig']['Model']={}\n",
    "config['HLSConfig']['Model']=config['Model']\n",
    "config['HLSConfig']['LayerName']=config['LayerName']\n",
    "\n",
    "del config['Model']\n",
    "del config['LayerName']\n",
    "config['AcceleratorConfig']={}\n",
    "config['AcceleratorConfig']['Interface'] = 'axi_stream'\n",
    "config['AcceleratorConfig']['Driver'] = 'python'\n",
    "config['AcceleratorConfig']['Precision']={}\n",
    "config['AcceleratorConfig']['Precision']['Input']= 'float'\n",
    "config['AcceleratorConfig']['Precision']['Output']= 'float'\n",
    "config['KerasModel'] = model\n",
    "config['HLSConfig']['LayerName']['q_conv2d_29']['ReuseFactor'] = 8\n",
    "config['HLSConfig']['LayerName']['q_conv2d_30']['ReuseFactor'] = 8\n",
    "config['HLSConfig']['LayerName']['q_conv2d_31']['ReuseFactor'] = 8\n",
    "config['HLSConfig']['LayerName']['q_dense_11']['ReuseFactor'] = 8\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Configuration\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = keras_to_hls(config)\n",
    "hls_model.compile()\n",
    "y_qkeras = model.predict(x_test)\n",
    "x_test = np.ascontiguousarray(x_test)\n",
    "y_hls = hls_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b5b8164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy baseline:  0.6667\n",
      "Accuracy pruned, quantized: 0.4678\n",
      "Accuracy hls4ml: 0.4664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_ref = load_model('model_cifar10_cnn/KERAS_check_best_model.h5')\n",
    "y_ref = model_ref.predict(x_test)\n",
    "\n",
    "print(\"Accuracy baseline:  {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_ref, axis=1))))\n",
    "print(\"Accuracy pruned, quantized: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))\n",
    "print(\"Accuracy hls4ml: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ee25da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff479daee10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "cifar10_classes=['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 9))\n",
    "_ = plotting.makeRoc(y_test, y_ref, cifar10_classes)\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.makeRoc(y_test, y_qkeras, cifar10_classes, linestyle='--')\n",
    "plt.gca().set_prop_cycle(None) # reset the colors\n",
    "_ = plotting.makeRoc(y_test, y_hls,cifar10_classes, linestyle=':')\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "lines = [Line2D([0], [0], ls='-'),\n",
    "         Line2D([0], [0], ls='--'),\n",
    "         Line2D([0], [0], ls=':')]\n",
    "from matplotlib.legend import Legend\n",
    "leg = Legend(ax, lines, labels=['baseline', 'pruned, quantized', 'hls4ml'],\n",
    "            loc='lower left', frameon=False)\n",
    "ax.add_artist(leg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b174a2f",
   "metadata": {},
   "source": [
    "# Synthesize\n",
    "Now let's synthesize this quantized, pruned model.\n",
    "\n",
    "**The synthesis will take a while**\n",
    "\n",
    "While the C-Synthesis is running, we can monitor the progress looking at the log file by opening a terminal from the notebook home, and executing:\n",
    "\n",
    "`tail -f mnist-hls-test4/vivado_hls.log`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57f155a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)\n",
      "  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019\n",
      "  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /workspace/home/Xilinx/Vivado/2019.2/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: [HLS 200-10] Running '/workspace/home/Xilinx/Vivado/2019.2/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "/workspace/home/Xilinx/Vivado/2019.2/tps/tcl/tcl8.5/tzdata/America/Denver can't be opened.\n",
      "INFO: [HLS 200-10] For user 'vitis-ai-user' on host 'eceutil1.gpu.snuhpc' (Linux_x86_64 version 4.15.0-76-generic) on Sun Nov 28 08:22:52 MST 2021\n",
      "INFO: [HLS 200-10] On os Ubuntu 18.04.5 LTS\n",
      "INFO: [HLS 200-10] In directory '/workspace/home/ymli/cifar_10_hls4ml/cifar10-hls-test4'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Opening project '/workspace/home/ymli/cifar_10_hls4ml/cifar10-hls-test4/myproject_cifar10_cnn4_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject_cifar10_cnn4_axi.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject_cifar10_cnn4.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_cifar10_cnn4_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Opening solution '/workspace/home/ymli/cifar_10_hls4ml/cifar10-hls-test4/myproject_cifar10_cnn4_prj/solution1'.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 5ns.\n",
      "INFO: [HLS 200-10] Setting target device to 'xczu7ev-ffvc1156-2-e'\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 60.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 60.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject_cifar10_cnn4.cpp' ... \n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/nnet_utils/nnet_dense_latency.h:64:9\n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/nnet_utils/nnet_dense_latency.h:79:2\n",
      "WARNING: [HLS 214-104] Only for-loops and functions support the dataflow: firmware/nnet_utils/nnet_dense_latency.h:76:9\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject_cifar10_cnn4.cpp:62:69\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject_cifar10_cnn4.cpp:62:73\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject_cifar10_cnn4.cpp:78:72\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject_cifar10_cnn4.cpp:78:76\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject_cifar10_cnn4.cpp:94:75\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject_cifar10_cnn4.cpp:94:80\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject_cifar10_cnn4.cpp:110:72\n",
      "WARNING: [HLS 214-113] Either use an argument of the function or declare the variable inside the dataflow loop body: firmware/myproject_cifar10_cnn4.cpp:110:77\n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject_cifar10_cnn4.cpp:35:2\n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject_cifar10_cnn4.cpp:36:5\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 13 issue(s) in file firmware/myproject_cifar10_cnn4.cpp\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject_cifar10_cnn4_axi.cpp' ... \n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject_cifar10_cnn4_axi.cpp:23:2\n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a canonical dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject_cifar10_cnn4_axi.cpp:35:5\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 2 issue(s) in file firmware/myproject_cifar10_cnn4_axi.cpp\n",
      "INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:52 ; elapsed = 00:02:34 . Memory (MB): peak = 954.555 ; gain = 523.035 ; free physical = 1702 ; free virtual = 168911\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:52 ; elapsed = 00:02:34 . Memory (MB): peak = 954.555 ; gain = 523.035 ; free physical = 1702 ; free virtual = 168911\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:228) in function 'void nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>(FORWARD_REFERENCE const&, ap_shift_reg<FORWARD_REFERENCE::value_type, FORWARD_REFERENCE::in_width> (*) [FORWARD_REFERENCE::n_chan], FORWARD_REFERENCE::value_type*)' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:228) in function 'void nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>(FORWARD_REFERENCE const&, ap_shift_reg<FORWARD_REFERENCE::value_type, FORWARD_REFERENCE::in_width> (*) [FORWARD_REFERENCE::n_chan], FORWARD_REFERENCE::value_type*)' completely with a factor of 1.\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>::operator[].1' into 'myproject_cifar10_cnn4_axi' (firmware/myproject_cifar10_cnn4_axi.cpp:27).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>::operator[]' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:223).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:234).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::limit' into 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_latency.h:57).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::limit' into 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_latency.h:57).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::limit' into 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10_mult>' (firmware/nnet_utils/nnet_dense_latency.h:57).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::limit' into 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' (firmware/nnet_utils/nnet_dense_latency.h:57).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' (firmware/nnet_utils/nnet_dense_latency.h:96).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' (firmware/nnet_utils/nnet_dense_latency.h:96).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10_mult>' (firmware/nnet_utils/nnet_dense_latency.h:96).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' (firmware/nnet_utils/nnet_dense_latency.h:96).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[]' into 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:284).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[]' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:195).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[]' into 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:284).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[]' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:195).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[]' into 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_conv_stream.h:284).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config11>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config7>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config3>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' into 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:276).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' into 'nnet::conv_2d_buffer_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' (firmware/nnet_utils/nnet_conv2d_stream.h:85).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::conv_2d_buffer_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' (firmware/nnet_utils/nnet_conv2d_stream.h:103).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config12>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config12>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config11>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config7>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config3>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::repack_stream<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, 256>' (firmware/nnet_utils/nnet_stream.h:88).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config12>' (firmware/nnet_utils/nnet_activation_stream.h:70).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config12>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:70).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:70).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[].1' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' (firmware/nnet_utils/nnet_conv_stream.h:223).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>::operator[].1' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' (firmware/nnet_utils/nnet_conv_stream.h:223).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' (firmware/nnet_utils/nnet_conv_stream.h:234).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce_pool<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, config5>' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:195).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::compute_pool_buffer_2d<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' into 'nnet::pooling2d_buffer_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:238).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::pooling2d_buffer_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' into 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:251).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[].1' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:223).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[].1' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_conv_stream.h:223).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:234).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' into 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:276).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' into 'nnet::conv_2d_buffer_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_conv2d_stream.h:85).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::conv_2d_buffer_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_conv2d_stream.h:103).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' (firmware/nnet_utils/nnet_conv_stream.h:234).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::reduce_pool<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, config9>' into 'nnet::compute_pool_buffer_2d<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:195).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::compute_pool_buffer_2d<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' into 'nnet::pooling2d_buffer_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:238).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::pooling2d_buffer_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' into 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:251).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::kernel_shift_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' into 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_conv_stream.h:234).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10_mult>' into 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_conv_stream.h:276).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::compute_output_buffer_2d<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' into 'nnet::conv_2d_buffer_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_conv2d_stream.h:85).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::conv_2d_buffer_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_conv2d_stream.h:103).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config14>' (firmware/nnet_utils/nnet_dense_stream.h:48).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>::operator[]' into 'nnet::repack_stream<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, 256>' (firmware/nnet_utils/nnet_stream.h:88).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_latency<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' (firmware/nnet_utils/nnet_dense_stream.h:22).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>::operator[]' into 'myproject_cifar10_cnn4_axi' (firmware/myproject_cifar10_cnn4_axi.cpp:39).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>::operator[]' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' (firmware/nnet_utils/nnet_activation_stream.h:175).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, linear_config15>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config14>' (firmware/nnet_utils/nnet_dense_stream.h:62).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>::operator[]' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' (firmware/nnet_utils/nnet_activation_stream.h:156).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, linear_config15>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:01:00 ; elapsed = 00:02:46 . Memory (MB): peak = 1082.555 ; gain = 651.035 ; free physical = 1556 ; free virtual = 168771\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n",
      "INFO: [XFORM 203-602] Inlining function 'fp_struct<double>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, double>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'fp_struct<double>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, double>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'fp_struct<double>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, double>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, double>' into 'generic_cast_IEEE754<int, double>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, double>' into '__hls_fptosi_double_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function '__hls_fptosi_double_i32' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' (firmware/nnet_utils/nnet_dense_latency.h:56->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' (firmware/nnet_utils/nnet_dense_latency.h:125->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:53) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:22->firmware/nnet_utils/nnet_pooling_stream.h:195->firmware/nnet_utils/nnet_pooling_stream.h:238->firmware/nnet_utils/nnet_pooling_stream.h:251) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function '__hls_fptosi_double_i32' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_dense_latency.h:56->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_dense_latency.h:125->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:22->firmware/nnet_utils/nnet_pooling_stream.h:195->firmware/nnet_utils/nnet_pooling_stream.h:238->firmware/nnet_utils/nnet_pooling_stream.h:251) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function '__hls_fptosi_double_i32' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_dense_latency.h:56->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10_mult>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_dense_latency.h:125->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function '__hls_fptosi_double_i32' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' (firmware/nnet_utils/nnet_dense_latency.h:56->firmware/nnet_utils/nnet_dense_stream.h:22) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' (firmware/nnet_utils/nnet_dense_latency.h:125->firmware/nnet_utils/nnet_dense_stream.h:22) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 8, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 8, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config16>' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' (firmware/nnet_utils/nnet_activation_stream.h:156) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' (firmware/nnet_utils/nnet_activation_stream.h:164) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config16>' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' (firmware/nnet_utils/nnet_activation_stream.h:166) automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [SYNCHK 200-23] firmware/myproject_cifar10_cnn4_axi.cpp:39: variable-indexed range selection may cause suboptimal QoR.\n",
      "INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:01:03 ; elapsed = 00:02:49 . Memory (MB): peak = 1087.297 ; gain = 655.777 ; free physical = 1509 ; free virtual = 168730\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'res.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'res.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'data.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' (firmware/myproject_cifar10_cnn4.cpp:32:1) on argument 'input_11.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:25). This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' (firmware/myproject_cifar10_cnn4.cpp:32:95) on argument 'layer16_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:26). This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-1103] Ignored data pack directive on non-struct variable 'out.data' (firmware/myproject_cifar10_cnn4_axi.cpp:5).\n",
      "WARNING: [XFORM 203-1103] Ignored data pack directive on non-struct variable 'in.data' (firmware/myproject_cifar10_cnn4_axi.cpp:4).\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_pack.data.V' (firmware/nnet_utils/nnet_activation_stream.h:170) into a 160-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:64) into a 96-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:64) into a 96-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:64) into a 96-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_pooling_stream.h:178) into a 256-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_pooling_stream.h:178) into a 256-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:42) into a 256-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:42) into a 256-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:42) into a 256-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:42) into a 160-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_dense_stream.h:58) into a 160-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_conv_stream.h:264) into a 256-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_conv_stream.h:264) into a 256-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_conv_stream.h:264) into a 256-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'ctype.data.V' (firmware/myproject_cifar10_cnn4_axi.cpp:24) into a 48-bit variable.\n",
      "WARNING: [XFORM 203-505] Ignore pipeline pragma in Loop whose tripcount is only 1 (firmware/nnet_utils/nnet_conv_stream.h:188) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>'.\n",
      "WARNING: [XFORM 203-505] Ignore pipeline pragma in Loop whose tripcount is only 1 (firmware/nnet_utils/nnet_conv_stream.h:188) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>'.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' (firmware/nnet_utils/nnet_activation_stream.h:146:59).\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'Loop-1' (firmware/nnet_utils/nnet_stream.h:82) in function 'nnet::repack_stream<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, 256>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReLUActLoop' (firmware/nnet_utils/nnet_activation_stream.h:60) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config8>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReLUActLoop' (firmware/nnet_utils/nnet_activation_stream.h:60) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config4>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReLUActLoop' (firmware/nnet_utils/nnet_activation_stream.h:60) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config12>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReadInputWidth' (firmware/nnet_utils/nnet_pooling_stream.h:234) in function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' for pipelining.\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:186) because its parent loop or function is pipelined.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReadInputWidth' (firmware/nnet_utils/nnet_pooling_stream.h:234) in function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' for pipelining.\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:186) because its parent loop or function is pipelined.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'LinearActLoop' (firmware/nnet_utils/nnet_activation_stream.h:38) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config7>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'LinearActLoop' (firmware/nnet_utils/nnet_activation_stream.h:38) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config3>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'LinearActLoop' (firmware/nnet_utils/nnet_activation_stream.h:38) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config11>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, linear_config15>' (firmware/nnet_utils/nnet_activation_stream.h:38:51).\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReadInputWidth' (firmware/nnet_utils/nnet_conv2d_stream.h:79) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReadInputWidth' (firmware/nnet_utils/nnet_conv2d_stream.h:79) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReadInputWidth' (firmware/nnet_utils/nnet_conv2d_stream.h:79) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' (firmware/nnet_utils/nnet_dense_latency.h:20:55).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_conv_stream.h:187:82).\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:187) because its parent loop or function is pipelined.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' (firmware/nnet_utils/nnet_conv_stream.h:187:82).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:187:82).\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:187) because its parent loop or function is pipelined.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' (firmware/nnet_utils/nnet_conv_stream.h:187:82).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:187:82).\n",
      "WARNING: [XFORM 203-505] Ignored pipeline directive for loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:187) because its parent loop or function is pipelined.\n",
      "INFO: [HLS 200-489] Unrolling loop 'SoftmaxExpPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:154) in function 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'SoftmaxInvPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:172) in function 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (firmware/nnet_utils/nnet_stream.h:86) in function 'nnet::repack_stream<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, 256>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1.2' (firmware/nnet_utils/nnet_stream.h:92) in function 'nnet::repack_stream<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, 256>' completely with a factor of 255.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:67) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config8>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:67) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config4>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:67) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config12>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:186) in function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PoolLoop' (firmware/nnet_utils/nnet_pooling_stream.h:190) in function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'FiltLoop' (firmware/nnet_utils/nnet_pooling_stream.h:186) in function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'PoolLoop' (firmware/nnet_utils/nnet_pooling_stream.h:190) in function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' completely with a factor of 4.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LinearPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:45) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config7>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LinearPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:45) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config3>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LinearPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:45) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config11>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LinearPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:45) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, linear_config15>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'DataPack' (firmware/nnet_utils/nnet_dense_stream.h:46) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config14>' completely with a factor of 256.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResPack' (firmware/nnet_utils/nnet_dense_stream.h:60) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config14>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:85) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' completely with a factor of 27.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:90) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:101) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:109) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' completely with a factor of 27.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:113) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' completely with a factor of 16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:120) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'CastLoop' (firmware/nnet_utils/nnet_conv_stream.h:282) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1' (firmware/nnet_utils/nnet_conv_stream.h:258) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 143.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:85) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 144.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:90) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:101) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:109) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 144.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:113) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:120) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'CastLoop' (firmware/nnet_utils/nnet_conv_stream.h:282) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.1' (firmware/nnet_utils/nnet_conv_stream.h:258) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 143.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:85) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 144.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:90) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:101) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:109) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 144.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:113) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:120) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'CastLoop' (firmware/nnet_utils/nnet_conv_stream.h:282) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product1' (firmware/nnet_utils/nnet_dense_latency.h:85) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' completely with a factor of 256.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Product2' (firmware/nnet_utils/nnet_dense_latency.h:90) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResetAccum' (firmware/nnet_utils/nnet_dense_latency.h:101) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Accum1' (firmware/nnet_utils/nnet_dense_latency.h:109) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' completely with a factor of 256.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Accum2' (firmware/nnet_utils/nnet_dense_latency.h:113) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_latency.h:120) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' completely with a factor of 10.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:219) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:226) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:228) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:187) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:189) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:190) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:201) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:219) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:226) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:187) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:189) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:190) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:201) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:219) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:226) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:228) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:187) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:189) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:190) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:201) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:219) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:226) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:187) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' completely with a factor of 1.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:189) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:190) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:201) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'UpdateBuffer' (firmware/nnet_utils/nnet_conv_stream.h:219) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferDataIn' (firmware/nnet_utils/nnet_conv_stream.h:226) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LineBufferShift' (firmware/nnet_utils/nnet_conv_stream.h:228) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftWidth' (firmware/nnet_utils/nnet_conv_stream.h:187) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 2.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftHeight' (firmware/nnet_utils/nnet_conv_stream.h:189) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelShiftChannel' (firmware/nnet_utils/nnet_conv_stream.h:190) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushHeight' (firmware/nnet_utils/nnet_conv_stream.h:199) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [HLS 200-489] Unrolling loop 'KernelPushChannel' (firmware/nnet_utils/nnet_conv_stream.h:201) in function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' completely with a factor of 3.\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V.4' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V.3' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V.2' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V.1' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning shift register array 'line_buffer.Array.V' .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer15_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:112) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'out_local.V.data.V' (firmware/myproject_cifar10_cnn4_axi.cpp:18) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer12_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:100) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer17_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:104) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer7_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:80) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer8_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:84) .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer3_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:64) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer4_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:68) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer11_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:96) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer9_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:88) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer5_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:72) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer6_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:76) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer2_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:60) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer10_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:92) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer14_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:108) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'in_local.V.data.V' (firmware/myproject_cifar10_cnn4_axi.cpp:17) .\n",
      "INFO: [XFORM 203-101] Partitioning array 'exp_res.V' (firmware/nnet_utils/nnet_activation_stream.h:146) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.2' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.4' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'pool_window.V' (firmware/nnet_utils/nnet_pooling_stream.h:172) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V.4'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.3' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'pool_window.V' (firmware/nnet_utils/nnet_pooling_stream.h:172) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V.3'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:35) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.2' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V.2'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res_out.i.i'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b2.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'mult.V' (firmware/nnet_utils/nnet_dense_latency.h:39) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_latency.h:40) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.1' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V.1'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res_out.i.i'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b6.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'mult.V' (firmware/nnet_utils/nnet_dense_latency.h:39) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_latency.h:40) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'kernel_data.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res_out.i.i'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b10.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'mult.V' (firmware/nnet_utils/nnet_dense_latency.h:39) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_latency.h:40) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b14.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'mult.V' (firmware/nnet_utils/nnet_dense_latency.h:39) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_latency.h:40) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:216) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:216) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:216) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:216) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:216) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer15_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:112) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'out_local.V.data.V' (firmware/myproject_cifar10_cnn4_axi.cpp:18) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer12_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:100) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer17_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:104) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer7_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:80) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer8_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:84) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer3_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:64) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer4_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:68) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer11_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:96) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer9_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:88) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer5_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:72) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer6_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:76) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer2_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:60) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer10_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:92) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer14_out.V.data.V' (firmware/myproject_cifar10_cnn4.cpp:108) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'in_local.V.data.V' (firmware/myproject_cifar10_cnn4_axi.cpp:17) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.4'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.3'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.2'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V.1'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'line_buffer.Array.V'  in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:216) in dimension 2 completely.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:216) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:216) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:216) in dimension 2 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'shift_buffer.V' (firmware/nnet_utils/nnet_conv_stream.h:216) in dimension 2 completely.\n",
      "INFO: [XFORM 203-602] Inlining function 'fp_struct<double>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, double>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'fp_struct<double>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, double>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'fp_struct<double>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, double>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, double>' into 'generic_cast_IEEE754<int, double>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, double>' into '__hls_fptosi_double_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function '__hls_fptosi_double_i32' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' (firmware/nnet_utils/nnet_dense_latency.h:56->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2_mult>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' (firmware/nnet_utils/nnet_dense_latency.h:125->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:53) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function '__hls_fptosi_double_i32' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_dense_latency.h:56->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config6_mult>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_dense_latency.h:125->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function '__hls_fptosi_double_i32' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_dense_latency.h:56->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config10_mult>' into 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_dense_latency.h:125->firmware/nnet_utils/nnet_conv_stream.h:276->firmware/nnet_utils/nnet_conv2d_stream.h:85->firmware/nnet_utils/nnet_conv2d_stream.h:103) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function '__hls_fptosi_double_i32' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' (firmware/nnet_utils/nnet_dense_latency.h:56->firmware/nnet_utils/nnet_dense_stream.h:22) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' (firmware/nnet_utils/nnet_dense_latency.h:125->firmware/nnet_utils/nnet_dense_stream.h:22) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:53) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 8, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 8, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config16>' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' (firmware/nnet_utils/nnet_activation_stream.h:156) automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config16>' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' (firmware/nnet_utils/nnet_activation_stream.h:166) automatically.\n",
      "INFO: [XFORM 203-721] Changing loop 'Loop_1_proc' (firmware/myproject_cifar10_cnn4_axi.cpp:23) to a process function for dataflow in function 'myproject_cifar10_cnn4_axi'.\n",
      "INFO: [XFORM 203-721] Changing loop 'Loop_2_proc' (firmware/myproject_cifar10_cnn4_axi.cpp:37) to a process function for dataflow in function 'myproject_cifar10_cnn4_axi'.\n",
      "INFO: [XFORM 203-712] Applying dataflow to function 'myproject_cifar10_cnn4', detected/extracted 16 process function(s): \n",
      "\t 'myproject_cifar10_cnn4_Block__proc'\n",
      "\t 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>'\n",
      "\t 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config3>'\n",
      "\t 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config4>'\n",
      "\t 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>'\n",
      "\t 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>'\n",
      "\t 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config7>'\n",
      "\t 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config8>'\n",
      "\t 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>'\n",
      "\t 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>'\n",
      "\t 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config11>'\n",
      "\t 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config12>'\n",
      "\t 'nnet::repack_stream<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, 256>'\n",
      "\t 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config14>'\n",
      "\t 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, linear_config15>'\n",
      "\t 'nnet::softmax<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>'.\n",
      "INFO: [XFORM 203-712] Applying dataflow to function 'myproject_cifar10_cnn4_axi', detected/extracted 5 process function(s): \n",
      "\t 'Block_codeRepl51_proc'\n",
      "\t 'Loop_1_proc459'\n",
      "\t 'myproject_cifar10_cnn4'\n",
      "\t 'Block_myproject_cifar10_cnn4_axi_.exit52_proc'\n",
      "\t 'Loop_2_proc'.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation_stream.h:60:74) to (firmware/nnet_utils/nnet_activation_stream.h:60:68) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config8>'... converting 49 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation_stream.h:60:74) to (firmware/nnet_utils/nnet_activation_stream.h:60:68) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config4>'... converting 49 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_activation_stream.h:60:74) to (firmware/nnet_utils/nnet_activation_stream.h:60:68) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config12>'... converting 49 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_common.h:55:43) in function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >'... converting 5 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_common.h:53:17) in function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >'... converting 5 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_common.h:45:20) to (firmware/nnet_utils/nnet_common.h:55:43) in function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >'... converting 13 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/myproject_cifar10_cnn4_axi.cpp:38:90) to (firmware/myproject_cifar10_cnn4_axi.cpp:37:49) in function 'Loop_2_proc'... converting 10 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/myproject_cifar10_cnn4_axi.cpp:28:25) to (firmware/myproject_cifar10_cnn4_axi.cpp:26:41) in function 'Loop_1_proc459'... converting 10 basic blocks.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:22->firmware/nnet_utils/nnet_pooling_stream.h:195->firmware/nnet_utils/nnet_pooling_stream.h:238->firmware/nnet_utils/nnet_pooling_stream.h:251) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_max<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:22->firmware/nnet_utils/nnet_pooling_stream.h:195->firmware/nnet_utils/nnet_pooling_stream.h:238->firmware/nnet_utils/nnet_pooling_stream.h:251) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55->firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' (firmware/nnet_utils/nnet_pooling_stream.h:86:5)...3 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' (firmware/nnet_utils/nnet_pooling_stream.h:86:5)...3 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' (firmware/nnet_utils/nnet_mult.h:20:9)...496 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' (firmware/nnet_utils/nnet_conv_stream.h:45:5)...81 expression(s) balanced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' (firmware/nnet_utils/nnet_conv_stream.h:45:5)...452 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' (firmware/nnet_utils/nnet_conv_stream.h:45:5)...448 expression(s) balanced.\n",
      "INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:08:06 ; elapsed = 00:10:11 . Memory (MB): peak = 10322.594 ; gain = 9891.074 ; free physical = 4959 ; free virtual = 164127\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_pooling_stream.h:233:80) in function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>'.\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_pooling_stream.h:233:80) in function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>'.\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_conv2d_stream.h:78:80) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>'.\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_conv2d_stream.h:78:80) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>'.\n",
      "INFO: [XFORM 203-541] Flattening a loop nest 'ReadInputHeight' (firmware/nnet_utils/nnet_conv2d_stream.h:78:80) in function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>'.\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' to 'softmax_latency<array,array,softmax_config16>' (firmware/nnet_utils/nnet_activation_stream.h:149:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::softmax<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, softmax_config16>' to 'softmax<array,array<ap_fixed,10u>,softmax_config16>' (firmware/nnet_utils/nnet_activation_stream.h:333:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config9>' to 'shift_line_buffer<array<ap_fixed,16u>,config9>' (firmware/nnet_utils/nnet_conv_stream.h:213:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::shift_line_buffer<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, config5>' to 'shift_line_buffer<array<ap_fixed,16u>,config5>' (firmware/nnet_utils/nnet_conv_stream.h:213:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, config2>' to 'shift_line_buffer<array<ap_fixed,3u>,config2>' (firmware/nnet_utils/nnet_conv_stream.h:213:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' to 'shift_line_buffer<array<ap_fixed,16u>,config6>' (firmware/nnet_utils/nnet_conv_stream.h:192:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::shift_line_buffer<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' to 'shift_line_buffer<array<ap_fixed,16u>,config10>' (firmware/nnet_utils/nnet_conv_stream.h:192:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::repack_stream<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, 256>' to 'repack_stream<array,array<ap_fixed,256u>,256>' (firmware/nnet_utils/nnet_stream.h:79:47)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config8>' to 'relu<array,array<ap_fixed,16u>,relu_config8>' (firmware/nnet_utils/nnet_activation_stream.h:60:68)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config4>' to 'relu<array,array<ap_fixed,16u>,relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:60:68)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, relu_config12>' to 'relu<array,array<ap_fixed,16u>,relu_config12>' (firmware/nnet_utils/nnet_activation_stream.h:60:68)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 10, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' to 'reduce<ap_fixed,10,Op_add<ap_fixed<18,8,0,0,0>>>' (firmware/nnet_utils/nnet_common.h:45:43)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config9>' to 'pooling2d_cl<array,array<ap_fixed,16u>,config9>' (firmware/nnet_utils/nnet_pooling_stream.h:86:5)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::pooling2d_cl<nnet::array<ap_fixed<6, 1, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config5>' to 'pooling2d_cl<array,array<ap_fixed,16u>,config5>' (firmware/nnet_utils/nnet_pooling_stream.h:86:5)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config7>' to 'linear<array,array<ap_fixed,16u>,linear_config7>' (firmware/nnet_utils/nnet_activation_stream.h:38:70)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config3>' to 'linear<array,array<ap_fixed,16u>,linear_config3>' (firmware/nnet_utils/nnet_activation_stream.h:38:70)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 16u>, linear_config11>' to 'linear<array,array<ap_fixed,16u>,linear_config11>' (firmware/nnet_utils/nnet_activation_stream.h:38:70)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 10u>, linear_config15>' to 'linear<array,array<ap_fixed,10u>,linear_config15>' (firmware/nnet_utils/nnet_activation_stream.h:38:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config14>' to 'dense_wrapper<ap_fixed,ap_fixed<16,6,5,3,0>,config14>' (firmware/nnet_utils/nnet_mult.h:20:9)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 256u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 10u>, config14>' to 'dense<array,array<ap_fixed<16,6,5,3,0>,10u>,config14>' (firmware/nnet_utils/nnet_dense_stream.h:41:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 3u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config2>' to 'conv_2d_cl<array,array<ap_fixed,16u>,config2>' (firmware/nnet_utils/nnet_conv_stream.h:45:5)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config6>' to 'conv_2d_cl<array,array<ap_fixed,16u>,config6>' (firmware/nnet_utils/nnet_conv_stream.h:45:5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [XFORM 203-631] Renaming function 'nnet::conv_2d_cl<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, config10>' to 'conv_2d_cl<array,array<ap_fixed,16u>,config10>' (firmware/nnet_utils/nnet_conv_stream.h:45:5)\n",
      "INFO: [HLS 200-472] Inferring partial write operation for 'out_data.data.V' (firmware/nnet_utils/nnet_stream.h:88:42)\n",
      "INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:09:26 ; elapsed = 00:11:33 . Memory (MB): peak = 10322.594 ; gain = 9891.074 ; free physical = 4958 ; free virtual = 164123\n",
      "INFO: [HLS 200-10] Starting hardware synthesis ...\n",
      "INFO: [HLS 200-10] Synthesizing 'myproject_cifar10_cnn4_axi' ...\n",
      "WARNING: [SYN 201-103] Legalizing function name 'shift_line_buffer<array<ap_fixed,3u>,config2>' to 'shift_line_buffer_array_ap_fixed_3u_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'conv_2d_cl<array,array<ap_fixed,16u>,config2>' to 'conv_2d_cl_array_array_ap_fixed_16u_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<array,array<ap_fixed,16u>,linear_config3>' to 'linear_array_array_ap_fixed_16u_linear_config3_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<array,array<ap_fixed,16u>,relu_config4>' to 'relu_array_array_ap_fixed_16u_relu_config4_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'shift_line_buffer<array<ap_fixed,16u>,config5>' to 'shift_line_buffer_array_ap_fixed_16u_config5_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'pooling2d_cl<array,array<ap_fixed,16u>,config5>' to 'pooling2d_cl_array_array_ap_fixed_16u_config5_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'shift_line_buffer<array<ap_fixed,16u>,config6>' to 'shift_line_buffer_array_ap_fixed_16u_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'conv_2d_cl<array,array<ap_fixed,16u>,config6>' to 'conv_2d_cl_array_array_ap_fixed_16u_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<array,array<ap_fixed,16u>,linear_config7>' to 'linear_array_array_ap_fixed_16u_linear_config7_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<array,array<ap_fixed,16u>,relu_config8>' to 'relu_array_array_ap_fixed_16u_relu_config8_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'shift_line_buffer<array<ap_fixed,16u>,config9>' to 'shift_line_buffer_array_ap_fixed_16u_config9_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'pooling2d_cl<array,array<ap_fixed,16u>,config9>' to 'pooling2d_cl_array_array_ap_fixed_16u_config9_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'shift_line_buffer<array<ap_fixed,16u>,config10>' to 'shift_line_buffer_array_ap_fixed_16u_config10_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'conv_2d_cl<array,array<ap_fixed,16u>,config10>' to 'conv_2d_cl_array_array_ap_fixed_16u_config10_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<array,array<ap_fixed,16u>,linear_config11>' to 'linear_array_array_ap_fixed_16u_linear_config11_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<array,array<ap_fixed,16u>,relu_config12>' to 'relu_array_array_ap_fixed_16u_relu_config12_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'repack_stream<array,array<ap_fixed,256u>,256>' to 'repack_stream_array_array_ap_fixed_256u_256_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_wrapper<ap_fixed,ap_fixed<16,6,5,3,0>,config14>' to 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config14_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense<array,array<ap_fixed<16,6,5,3,0>,10u>,config14>' to 'dense_array_array_ap_fixed_16_6_5_3_0_10u_config14_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<array,array<ap_fixed,10u>,linear_config15>' to 'linear_array_array_ap_fixed_10u_linear_config15_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'reduce<ap_fixed,10,Op_add<ap_fixed<18,8,0,0,0>>>' to 'reduce_ap_fixed_10_Op_add_ap_fixed_18_8_0_0_0_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'softmax_latency<array,array,softmax_config16>' to 'softmax_latency_array_array_softmax_config16_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'softmax<array,array<ap_fixed,10u>,softmax_config16>' to 'softmax_array_array_ap_fixed_10u_softmax_config16_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'Block_myproject_cifar10_cnn4_axi_.exit52_proc' to 'Block_myproject_cifar10_cnn4_axi_exit52_proc'.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'Loop_1_proc459' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 693.94 seconds; current allocated memory: 782.506 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.48 seconds; current allocated memory: 782.947 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'shift_line_buffer_array_ap_fixed_3u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'shift_line_buffer<array<ap_fixed,3u>,config2>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.61 seconds; current allocated memory: 783.225 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.33 seconds; current allocated memory: 783.465 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'conv_2d_cl_array_array_ap_fixed_16u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReadInputHeight_ReadInputWidth'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 8, Final II = 4, Depth = 4.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.75 seconds; current allocated memory: 785.483 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.71 seconds; current allocated memory: 787.704 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_array_array_ap_fixed_16u_linear_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'LinearActLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.94 seconds; current allocated memory: 788.013 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 788.396 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_array_array_ap_fixed_16u_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [SCHED 204-61] Pipelining loop 'ReLUActLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 3.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.6 seconds; current allocated memory: 789.663 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.32 seconds; current allocated memory: 791.448 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'shift_line_buffer_array_ap_fixed_16u_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'shift_line_buffer<array<ap_fixed,16u>,config5>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.57 seconds; current allocated memory: 792.089 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.61 seconds; current allocated memory: 792.600 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'pooling2d_cl_array_array_ap_fixed_16u_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReadInputHeight_ReadInputWidth'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 3.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.79 seconds; current allocated memory: 793.786 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.25 seconds; current allocated memory: 795.188 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'shift_line_buffer_array_ap_fixed_16u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'shift_line_buffer<array<ap_fixed,16u>,config6>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.45 seconds; current allocated memory: 796.203 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.91 seconds; current allocated memory: 797.283 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'conv_2d_cl_array_array_ap_fixed_16u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReadInputHeight_ReadInputWidth'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 8, Final II = 4, Depth = 4.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.5 seconds; current allocated memory: 807.950 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 10.57 seconds; current allocated memory: 818.860 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_array_array_ap_fixed_16u_linear_config7_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'LinearActLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 8.89 seconds; current allocated memory: 819.635 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.35 seconds; current allocated memory: 820.019 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_array_array_ap_fixed_16u_relu_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReLUActLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 3.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.62 seconds; current allocated memory: 821.267 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.3 seconds; current allocated memory: 823.052 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'shift_line_buffer_array_ap_fixed_16u_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'shift_line_buffer<array<ap_fixed,16u>,config9>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.61 seconds; current allocated memory: 823.672 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 824.185 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'pooling2d_cl_array_array_ap_fixed_16u_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReadInputHeight_ReadInputWidth'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 3.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.81 seconds; current allocated memory: 825.426 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.12 seconds; current allocated memory: 826.831 MB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'shift_line_buffer_array_ap_fixed_16u_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'shift_line_buffer<array<ap_fixed,16u>,config10>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.37 seconds; current allocated memory: 827.796 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.9 seconds; current allocated memory: 828.877 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'conv_2d_cl_array_array_ap_fixed_16u_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReadInputHeight_ReadInputWidth'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 8, Final II = 4, Depth = 4.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.5 seconds; current allocated memory: 839.506 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 10.48 seconds; current allocated memory: 850.559 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_array_array_ap_fixed_16u_linear_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'LinearActLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 8.75 seconds; current allocated memory: 851.337 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.33 seconds; current allocated memory: 851.722 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_array_array_ap_fixed_16u_relu_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReLUActLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 3.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.6 seconds; current allocated memory: 852.972 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.37 seconds; current allocated memory: 854.756 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'repack_stream_array_array_ap_fixed_256u_256_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'Loop 1'.\n",
      "WARNING: [SCHED 204-69] Unable to schedule 'store' operation ('out_data_data_V_addr_257_write_ln88', firmware/nnet_utils/nnet_stream.h:88) of variable 'shl_ln728_2', firmware/nnet_utils/nnet_stream.h:88 on array 'out_data.data.V', firmware/nnet_utils/nnet_stream.h:79 due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'out_data_data_V'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 136, Depth = 138.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 9.34 seconds; current allocated memory: 858.782 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 4.58 seconds; current allocated memory: 865.047 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config14_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'dense_wrapper<ap_fixed,ap_fixed<16,6,5,3,0>,config14>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 8, Final II = 3, Depth = 3.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 5.72 seconds; current allocated memory: 874.151 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 10.46 seconds; current allocated memory: 884.504 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_array_array_ap_fixed_16_6_5_3_0_10u_config14_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 8.85 seconds; current allocated memory: 886.277 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.76 seconds; current allocated memory: 889.750 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_array_array_ap_fixed_10u_linear_config15_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<array,array<ap_fixed,10u>,linear_config15>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.48 seconds; current allocated memory: 890.389 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.33 seconds; current allocated memory: 890.632 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'reduce_ap_fixed_10_Op_add_ap_fixed_18_8_0_0_0_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'reduce<ap_fixed,10,Op_add<ap_fixed<18,8,0,0,0>>>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.42 seconds; current allocated memory: 890.967 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 891.304 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'softmax_latency_array_array_softmax_config16_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'softmax_latency<array,array,softmax_config16>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 6.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.66 seconds; current allocated memory: 891.741 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.66 seconds; current allocated memory: 892.364 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'softmax_array_array_ap_fixed_10u_softmax_config16_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.73 seconds; current allocated memory: 892.556 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.33 seconds; current allocated memory: 892.789 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject_cifar10_cnn4' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.78 seconds; current allocated memory: 895.360 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 13.7 seconds; current allocated memory: 911.558 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'Block_myproject_cifar10_cnn4_axi_exit52_proc' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 7.75 seconds; current allocated memory: 914.263 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 914.442 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'Loop_2_proc' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 914.698 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 915.040 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject_cifar10_cnn4_axi' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 915.296 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 4.62 seconds; current allocated memory: 919.233 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'Loop_1_proc459' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_cifar10_cnn4_axi_fpext_32ns_64_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'Loop_1_proc459'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 4.78 seconds; current allocated memory: 922.773 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'shift_line_buffer_array_ap_fixed_3u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_buffer_Array_V_2_0_0' to 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_bufferbkb' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_buffer_Array_V_2_1_0' to 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_buffercud' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_buffer_Array_V_2_0_1' to 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_bufferdEe' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_buffer_Array_V_2_1_1' to 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_buffereOg' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_buffer_Array_V_2_0_2' to 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_bufferfYi' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_buffer_Array_V_2_1_2' to 'shift_line_buffer_array_ap_fixed_3u_config2_s_line_bufferg8j' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'shift_line_buffer_array_ap_fixed_3u_config2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.99 seconds; current allocated memory: 926.953 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'conv_2d_cl_array_array_ap_fixed_16u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'pX_2' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sX_2' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pY_2' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sY_2' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_4' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_5' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_6' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_7' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_8' is power-on initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_12' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_13' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_14' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_15' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_16' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_17' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_21' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_22' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_23' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_24' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_25' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_2_26' is power-on initialization.\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_2d_cl_array_array_ap_fixed_16u_config2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.02 seconds; current allocated memory: 931.986 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_array_array_ap_fixed_16u_linear_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_array_array_ap_fixed_16u_linear_config3_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 8.12 seconds; current allocated memory: 941.928 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_array_array_ap_fixed_16u_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_array_array_ap_fixed_16u_relu_config4_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.05 seconds; current allocated memory: 945.868 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'shift_line_buffer_array_ap_fixed_16u_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_0' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffehbi' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_1' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffeibs' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_2' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffejbC' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_3' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffekbM' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_4' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffelbW' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_5' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffemb6' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_6' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffencg' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_7' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffeocq' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_8' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffepcA' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_9' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffeqcK' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_10' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffercU' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_11' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffesc4' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_12' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffetde' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_13' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffeudo' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_14' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffevdy' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffer_Array_V_3_0_15' to 'shift_line_buffer_array_ap_fixed_16u_config5_s_line_buffewdI' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'shift_line_buffer_array_ap_fixed_16u_config5_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 7.52 seconds; current allocated memory: 962.540 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'pooling2d_cl_array_array_ap_fixed_16u_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'pX_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sX_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pY_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sY_1' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_16' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_17' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_18' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_19' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_20' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_21' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_22' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_23' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_24' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_25' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_26' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_27' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_28' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_29' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_30' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_31' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_48' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_49' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_50' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_51' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_52' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_53' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_54' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_55' is power-on initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_56' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_57' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_58' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_59' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_60' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_61' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_62' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_3_63' is power-on initialization.\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'pooling2d_cl_array_array_ap_fixed_16u_config5_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 4.32 seconds; current allocated memory: 972.054 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'shift_line_buffer_array_ap_fixed_16u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_37' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_94' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_138' is power-on initialization.\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_0' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffexdS' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_0' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeyd2' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_1' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffezec' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_1' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeAem' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_2' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeBew' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_2' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeCeG' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_3' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeDeQ' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_3' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeEe0' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_4' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeFfa' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_4' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeGfk' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_5' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeHfu' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_5' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeIfE' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_6' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeJfO' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_6' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeKfY' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_7' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeLf8' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_7' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeMgi' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_8' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeNgs' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_8' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeOgC' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_9' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffePgM' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_9' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeQgW' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_10' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeRg6' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_10' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeShg' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_11' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeThq' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_11' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeUhA' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_12' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeVhK' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_12' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeWhU' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_13' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeXh4' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_13' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeYie' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_14' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffeZio' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_14' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffe0iy' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_0_15' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffe1iI' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffer_Array_V_1_1_15' to 'shift_line_buffer_array_ap_fixed_16u_config6_s_line_buffe2iS' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'shift_line_buffer_array_ap_fixed_16u_config6_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 7.73 seconds; current allocated memory: 1023.739 MB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'conv_2d_cl_array_array_ap_fixed_16u_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_84' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_85' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_86' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_87' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_88' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_89' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_90' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_91' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_92' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_93' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_95' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_96' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_97' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_98' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_99' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_100' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_102' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_103' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_104' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_105' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_106' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_107' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_108' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_109' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_110' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_111' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_112' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_113' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_114' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_115' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_116' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_117' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_118' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_119' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_120' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_121' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_122' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_123' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_124' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_125' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_126' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_127' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_128' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_129' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_130' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_131' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_132' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_133' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_134' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_135' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_136' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_137' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_139' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_140' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_141' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_142' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_143' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pX_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sX_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pY_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sY_3' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_16' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_17' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_18' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_19' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_20' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_21' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_22' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_23' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_24' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_25' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_26' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_27' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_28' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_29' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_30' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_31' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_32' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_33' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_34' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_35' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_36' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_38' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_39' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_40' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_41' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_42' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_43' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_44' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_45' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_46' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_47' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_64' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_65' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_66' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_67' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_68' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_69' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_70' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_71' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_72' is power-on initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_73' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_74' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_75' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_76' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_77' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_78' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_79' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_80' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_81' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_82' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_1_83' is power-on initialization.\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_2d_cl_array_array_ap_fixed_16u_config6_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 10.2 seconds; current allocated memory: 1.043 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_array_array_ap_fixed_16u_linear_config7_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_array_array_ap_fixed_16u_linear_config7_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 45.13 seconds; current allocated memory: 1.091 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_array_array_ap_fixed_16u_relu_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_array_array_ap_fixed_16u_relu_config8_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.54 seconds; current allocated memory: 1.094 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'shift_line_buffer_array_ap_fixed_16u_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_0' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffe3i2' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_1' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffe4jc' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_2' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffe5jm' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_3' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffe6jw' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_4' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffe7jG' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_5' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffe8jQ' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_6' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffe9j0' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_7' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffebak' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_8' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffebbk' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_9' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffebck' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_10' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffebdk' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_11' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffebek' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_12' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffebfk' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_13' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffebgk' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_14' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffebhl' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffer_Array_V_4_0_15' to 'shift_line_buffer_array_ap_fixed_16u_config9_s_line_buffebil' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'shift_line_buffer_array_ap_fixed_16u_config9_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 8.74 seconds; current allocated memory: 1.111 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'pooling2d_cl_array_array_ap_fixed_16u_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'pX' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sX' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pY' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sY' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_16' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_17' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_18' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_19' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_20' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_21' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_22' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_23' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_24' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_25' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_26' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_27' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_28' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_29' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_30' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_31' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_48' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_49' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_50' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_51' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_52' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_53' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_54' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_55' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_56' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_57' is power-on initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_58' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_59' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_60' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_61' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_62' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_4_63' is power-on initialization.\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'pooling2d_cl_array_array_ap_fixed_16u_config9_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 5.51 seconds; current allocated memory: 1.120 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'shift_line_buffer_array_ap_fixed_16u_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_124' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_41' is power-on initialization.\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_0' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbjl' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_0' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbkl' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_1' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbll' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_1' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbml' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_2' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbnm' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_2' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbom' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_3' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbpm' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_3' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbqm' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_4' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbrm' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_4' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbsm' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_5' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbtn' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_5' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbun' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_6' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbvn' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_6' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbwn' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_7' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbxn' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_7' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbyn' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_8' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbzo' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_8' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbAo' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_9' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbBo' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_9' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbCo' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_10' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbDo' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_10' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbEo' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_11' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbFp' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_11' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbGp' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_12' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbHp' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_12' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbIp' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_13' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbJp' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_13' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbKp' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_14' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbLp' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_14' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbMq' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_0_15' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbNq' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffer_Array_V_1381_15' to 'shift_line_buffer_array_ap_fixed_16u_config10_s_line_buffbOq' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'shift_line_buffer_array_ap_fixed_16u_config10_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 9.5 seconds; current allocated memory: 1.171 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'conv_2d_cl_array_array_ap_fixed_16u_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_85' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_86' is power-on initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_87' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_88' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_89' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_90' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_91' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_92' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_93' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_94' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_95' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_96' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_97' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_98' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_99' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_100' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_101' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_102' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_103' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_104' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_105' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_106' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_107' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_108' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_109' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_110' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_111' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_112' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_113' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_114' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_115' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_116' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_117' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_118' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_119' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_120' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_121' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_122' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_123' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_125' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_126' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_127' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_128' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_129' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_130' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_131' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_132' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_133' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_134' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_135' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_136' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_137' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_138' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_139' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_140' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_141' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_142' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_143' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pX_4' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sX_4' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'pY_4' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'sY_4' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_16' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_17' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_18' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_19' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_20' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_21' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_22' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_23' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_24' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_25' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_26' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_27' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_28' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_29' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_30' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_31' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_32' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_33' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_34' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_35' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_36' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_37' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_38' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_39' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_40' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_42' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_43' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_44' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_45' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_46' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_47' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_64' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_65' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_66' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_67' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_68' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_70' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_71' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_72' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_73' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_74' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_75' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_76' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_77' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_78' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_79' is power-on initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_80' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_81' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_82' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_83' is power-on initialization.\n",
      "WARNING: [RTGEN 206-101] Register 'kernel_data_V_84' is power-on initialization.\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'conv_2d_cl_array_array_ap_fixed_16u_config10_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 11.63 seconds; current allocated memory: 1.215 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_array_array_ap_fixed_16u_linear_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_array_array_ap_fixed_16u_linear_config11_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 46.87 seconds; current allocated memory: 1.261 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_array_array_ap_fixed_16u_relu_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_array_array_ap_fixed_16u_relu_config12_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 4.26 seconds; current allocated memory: 1.265 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'repack_stream_array_array_ap_fixed_256u_256_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'repack_stream_array_array_ap_fixed_256u_256_s_out_data_data_V' to 'repack_stream_array_array_ap_fixed_256u_256_s_out_data_dabPq' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'repack_stream_array_array_ap_fixed_256u_256_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 10.07 seconds; current allocated memory: 1.281 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config14_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config14_s' is 8308 from HDL expression: (1'b1 == ap_CS_fsm_state1)\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config14_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 18.39 seconds; current allocated memory: 1.317 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_array_array_ap_fixed_16_6_5_3_0_10u_config14_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_array_array_ap_fixed_16_6_5_3_0_10u_config14_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 58.08 seconds; current allocated memory: 1.436 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_array_array_ap_fixed_10u_linear_config15_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_array_array_ap_fixed_10u_linear_config15_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 10.59 seconds; current allocated memory: 1.442 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'reduce_ap_fixed_10_Op_add_ap_fixed_18_8_0_0_0_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'reduce_ap_fixed_10_Op_add_ap_fixed_18_8_0_0_0_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 5.45 seconds; current allocated memory: 1.443 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'softmax_latency_array_array_softmax_config16_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'softmax_latency_array_array_softmax_config16_s_invert_table2' to 'softmax_latency_array_array_softmax_config16_s_invert_tabbQq' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax_latency_array_array_softmax_config16_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 6.75 seconds; current allocated memory: 1.446 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'softmax_array_array_ap_fixed_10u_softmax_config16_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax_array_array_ap_fixed_10u_softmax_config16_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 7.07 seconds; current allocated memory: 1.448 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject_cifar10_cnn4' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'start_for_linear_array_array_ap_fixed_16u_linear_config11_U0' to 'start_for_linear_array_array_ap_fixed_16u_linear_config11bRq' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_10u_config14_U0' to 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_10u_confibSr' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'start_for_linear_array_array_ap_fixed_10u_linear_config15_U0' to 'start_for_linear_array_array_ap_fixed_10u_linear_config15bTr' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'start_for_softmax_array_array_ap_fixed_10u_softmax_config16_U0' to 'start_for_softmax_array_array_ap_fixed_10u_softmax_configbUr' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject_cifar10_cnn4'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 9.44 seconds; current allocated memory: 1.466 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'Block_myproject_cifar10_cnn4_axi_exit52_proc' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'Block_myproject_cifar10_cnn4_axi_exit52_proc'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 21.76 seconds; current allocated memory: 1.483 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'Loop_2_proc' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_cifar10_cnn4_axi_mux_104_16_1_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'Loop_2_proc'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 5.74 seconds; current allocated memory: 1.484 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject_cifar10_cnn4_axi' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_cifar10_cnn4_axi/in_data' to 'axis' (register, both mode).\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_cifar10_cnn4_axi/in_last_V' to 'axis' (register, both mode).\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_cifar10_cnn4_axi/out_data' to 'axis' (register, both mode).\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_cifar10_cnn4_axi/out_last_V' to 'axis' (register, both mode).\n",
      "INFO: [RTGEN 206-500] Setting interface mode on function 'myproject_cifar10_cnn4_axi' to 'ap_ctrl_none'.\n",
      "WARNING: [HLS 200-631] Ignoring ap_ctrl_none interface for myproject_cifar10_cnn4_axi due to Block_myproject_cifar10_cnn4_axi_.exit52_proc with non-FIFO I/O\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject_cifar10_cnn4_axi'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 6.75 seconds; current allocated memory: 1.486 GB.\n",
      "INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were satisfied.\n",
      "INFO: [HLS 200-789] **** Estimated Fmax: 229.93 MHz\n",
      "INFO: [RTMG 210-278] Implementing memory 'repack_stream_array_array_ap_fixed_256u_256_s_out_data_dabPq_ram (RAM)' using block RAMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'softmax_latency_array_array_softmax_config16_s_exp_table1_rom' using block ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'softmax_latency_array_array_softmax_config16_s_invert_tabbQq_rom' using auto ROMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_0_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_1_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_2_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_3_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_4_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_5_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_6_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_7_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_8_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_9_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_10_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_11_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_12_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_13_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_14_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer2_out_V_data_15_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_0_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_1_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_2_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_3_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_4_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_5_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_6_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_7_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_8_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_9_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_10_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_11_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_12_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_13_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_14_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer3_out_V_data_15_V_U(fifo_w16_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_0_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_1_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_2_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_3_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_4_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_5_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_6_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_7_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_8_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_9_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_10_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_11_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_12_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_13_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_14_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer4_out_V_data_15_V_U(fifo_w6_d900_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_0_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_1_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_2_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_3_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_4_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_5_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_6_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_7_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_8_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_9_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_10_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_11_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_12_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_13_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_14_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer5_out_V_data_15_V_U(fifo_w16_d225_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_0_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_1_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_2_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_3_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_4_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_5_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_6_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_7_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_8_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_9_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_10_V_U(fifo_w16_d169_A)' using Block RAMs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_11_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_12_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_13_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_14_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer6_out_V_data_15_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_0_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_1_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_2_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_3_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_4_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_5_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_6_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_7_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_8_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_9_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_10_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_11_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_12_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_13_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_14_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer7_out_V_data_15_V_U(fifo_w16_d169_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_0_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_1_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_2_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_3_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_4_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_5_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_6_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_7_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_8_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_9_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_10_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_11_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_12_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_13_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_14_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer8_out_V_data_15_V_U(fifo_w6_d169_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_0_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_1_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_2_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_3_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_4_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_5_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_6_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_7_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_8_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_9_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_10_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_11_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_12_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_13_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_14_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer9_out_V_data_15_V_U(fifo_w16_d36_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_0_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_1_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_2_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_3_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_4_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_5_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_6_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_7_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_8_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_9_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_10_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_11_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_12_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_13_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_14_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer10_out_V_data_15_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_0_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_1_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_2_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_3_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_4_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_5_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_6_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_7_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_8_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_9_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_10_V_U(fifo_w16_d16_A)' using Shift Registers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_11_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_12_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_13_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_14_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer11_out_V_data_15_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_0_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_1_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_2_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_3_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_4_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_5_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_6_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_7_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_8_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_9_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_10_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_11_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_12_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_13_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_14_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'layer12_out_V_data_15_V_U(fifo_w6_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_linear_array_array_ap_fixed_16u_linear_config3_U0_U(start_for_linear_array_array_ap_fixed_16u_linear_config3_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_relu_array_array_ap_fixed_16u_relu_config4_U0_U(start_for_relu_array_array_ap_fixed_16u_relu_config4_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_pooling2d_cl_array_array_ap_fixed_16u_config5_U0_U(start_for_pooling2d_cl_array_array_ap_fixed_16u_config5_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_conv_2d_cl_array_array_ap_fixed_16u_config6_U0_U(start_for_conv_2d_cl_array_array_ap_fixed_16u_config6_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_linear_array_array_ap_fixed_16u_linear_config7_U0_U(start_for_linear_array_array_ap_fixed_16u_linear_config7_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_relu_array_array_ap_fixed_16u_relu_config8_U0_U(start_for_relu_array_array_ap_fixed_16u_relu_config8_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_pooling2d_cl_array_array_ap_fixed_16u_config9_U0_U(start_for_pooling2d_cl_array_array_ap_fixed_16u_config9_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_conv_2d_cl_array_array_ap_fixed_16u_config10_U0_U(start_for_conv_2d_cl_array_array_ap_fixed_16u_config10_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_linear_array_array_ap_fixed_16u_linear_config11bRq_U(start_for_linear_array_array_ap_fixed_16u_linear_config11bRq)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_relu_array_array_ap_fixed_16u_relu_config12_U0_U(start_for_relu_array_array_ap_fixed_16u_relu_config12_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_repack_stream_array_array_ap_fixed_256u_256_U0_U(start_for_repack_stream_array_array_ap_fixed_256u_256_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_10u_confibSr_U(start_for_dense_array_array_ap_fixed_16_6_5_3_0_10u_confibSr)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_linear_array_array_ap_fixed_10u_linear_config15bTr_U(start_for_linear_array_array_ap_fixed_10u_linear_config15bTr)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_softmax_array_array_ap_fixed_10u_softmax_configbUr_U(start_for_softmax_array_array_ap_fixed_10u_softmax_configbUr)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_0_V_U(fifo_w16_d3072_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_1_V_U(fifo_w16_d3072_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_2_V_U(fifo_w16_d3072_A)' using Block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'is_last_0_i_loc_channel_U(fifo_w1_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_0_V_U(fifo_w16_d10_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_1_V_U(fifo_w16_d10_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_2_V_U(fifo_w16_d10_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_3_V_U(fifo_w16_d10_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_4_V_U(fifo_w16_d10_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_5_V_U(fifo_w16_d10_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_6_V_U(fifo_w16_d10_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_7_V_U(fifo_w16_d10_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_8_V_U(fifo_w16_d10_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_9_V_U(fifo_w16_d10_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_0_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_1_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_2_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_3_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_4_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_5_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_6_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_7_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_8_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'tmp_data_V_9_U(fifo_w16_d2_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_myproject_cifar10_cnn4_U0_U(start_for_myproject_cifar10_cnn4_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_Block_myproject_cifar10_cnn4_axi_exit52_proc_U0_U(start_for_Block_myproject_cifar10_cnn4_axi_exit52_proc_U0)' using Shift Registers.\n",
      "INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:14:39 ; elapsed = 00:27:04 . Memory (MB): peak = 10322.594 ; gain = 9891.074 ; free physical = 5277 ; free virtual = 164155\n",
      "INFO: [VHDL 208-304] Generating VHDL RTL for myproject_cifar10_cnn4_axi.\n",
      "INFO: [VLOG 209-307] Generating Verilog RTL for myproject_cifar10_cnn4_axi.\n",
      "***** C/RTL SYNTHESIS COMPLETED IN 0h26m19s *****\n",
      "***** EXPORT IP *****\n",
      "INFO: [IMPL 213-8] Exporting RTL as a Vivado IP.\n",
      "\n",
      "****** Vivado v2019.2 (64-bit)\n",
      "  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019\n",
      "  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source run_ippack.tcl -notrace\n",
      "create_project: Time (s): cpu = 00:00:04 ; elapsed = 00:00:28 . Memory (MB): peak = 1512.398 ; gain = 78.016 ; free physical = 4893 ; free virtual = 163862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [IP_Flow 19-234] Refreshing IP repositories\n",
      "INFO: [IP_Flow 19-1704] No user IP repositories specified\n",
      "INFO: [IP_Flow 19-2313] Loaded Vivado IP repository '/workspace/home/Xilinx/Vivado/2019.2/data/ip'.\n",
      "WARNING: [IP_Flow 19-4832] The IP name 'myproject_cifar10_cnn4_axi_ap_fpext_0_no_dsp_32' you have specified is long. The Windows operating system has path length limitations. It is recommended you use shorter names to reduce the likelihood of issues.\n",
      "create_ip: Time (s): cpu = 00:00:04 ; elapsed = 00:00:26 . Memory (MB): peak = 1605.574 ; gain = 93.176 ; free physical = 4862 ; free virtual = 163836\n",
      "INFO: [IP_Flow 19-1686] Generating 'Synthesis' target for IP 'myproject_cifar10_cnn4_axi_ap_fpext_0_no_dsp_32'...\n",
      "INFO: [IP_Flow 19-1686] Generating 'Simulation' target for IP 'myproject_cifar10_cnn4_axi_ap_fpext_0_no_dsp_32'...\n",
      "INFO: [IP_Flow 19-234] Refreshing IP repositories\n",
      "INFO: [IP_Flow 19-1704] No user IP repositories specified\n",
      "INFO: [IP_Flow 19-2313] Loaded Vivado IP repository '/workspace/home/Xilinx/Vivado/2019.2/data/ip'.\n",
      "ipx::update_checksums: Time (s): cpu = 00:00:00.63 ; elapsed = 00:00:22 . Memory (MB): peak = 1608.543 ; gain = 0.000 ; free physical = 4862 ; free virtual = 163839\n",
      "ipx::archive_core: Time (s): cpu = 00:00:00.45 ; elapsed = 00:00:05 . Memory (MB): peak = 1608.543 ; gain = 0.000 ; free physical = 4857 ; free virtual = 163836\n",
      "INFO: [Common 17-206] Exiting Vivado at Sun Nov 28 08:57:07 2021...\n",
      "***** EXPORT IP COMPLETED IN 0h7m19s *****\n",
      "INFO: [HLS 200-112] Total elapsed time: 2064.03 seconds; peak allocated memory: 1.486 GB.\n",
      "INFO: [Common 17-206] Exiting vivado_hls at Sun Nov 28 08:57:11 2021...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EstimatedClockPeriod': '4.349',\n",
       " 'BestLatency': '14337',\n",
       " 'WorstLatency': '14337',\n",
       " 'IntervalMin': '14338',\n",
       " 'IntervalMax': '14338',\n",
       " 'BRAM_18K': '147',\n",
       " 'DSP48E': '140',\n",
       " 'FF': '36357',\n",
       " 'LUT': '105271',\n",
       " 'URAM': '0',\n",
       " 'AvailableBRAM_18K': '624',\n",
       " 'AvailableDSP48E': '1728',\n",
       " 'AvailableFF': '460800',\n",
       " 'AvailableLUT': '230400',\n",
       " 'AvailableURAM': '96'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PATH'] = '/workspace/home/Xilinx/Vivado/2019.2/bin:' + os.environ['PATH']\n",
    "hls_model.build(csim=False,synth=True,export=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87af97f6",
   "metadata": {},
   "source": [
    "## Check the reports\n",
    "Print out the reports generated by Vivado HLS. Pay attention to the Utilization Estimates' section in particular this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39f69a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 solution(s) in cifar10-hls-test4/myproject_cifar10_cnn4_prj.\n",
      "Reports for solution \"solution1\":\n",
      "\n",
      "C simulation report not found.\n",
      "SYNTHESIS REPORT:\n",
      "================================================================\n",
      "== Vivado HLS Report for 'myproject_cifar10_cnn4_axi'\n",
      "================================================================\n",
      "* Date:           Sun Nov 28 08:42:30 2021\n",
      "\n",
      "* Version:        2019.2 (Build 2704478 on Wed Nov 06 22:10:23 MST 2019)\n",
      "* Project:        myproject_cifar10_cnn4_prj\n",
      "* Solution:       solution1\n",
      "* Product family: zynquplus\n",
      "* Target device:  xczu7ev-ffvc1156-2-e\n",
      "\n",
      "\n",
      "================================================================\n",
      "== Performance Estimates\n",
      "================================================================\n",
      "+ Timing: \n",
      "    * Summary: \n",
      "    +--------+---------+----------+------------+\n",
      "    |  Clock |  Target | Estimated| Uncertainty|\n",
      "    +--------+---------+----------+------------+\n",
      "    |ap_clk  | 5.00 ns | 4.349 ns |   0.62 ns  |\n",
      "    +--------+---------+----------+------------+\n",
      "\n",
      "+ Latency: \n",
      "    * Summary: \n",
      "    +---------+---------+-----------+-----------+-------+-------+----------+\n",
      "    |  Latency (cycles) |   Latency (absolute)  |    Interval   | Pipeline |\n",
      "    |   min   |   max   |    min    |    max    |  min  |  max  |   Type   |\n",
      "    +---------+---------+-----------+-----------+-------+-------+----------+\n",
      "    |    14337|    14337| 71.685 us | 71.685 us |  14338|  14338| dataflow |\n",
      "    +---------+---------+-----------+-----------+-------+-------+----------+\n",
      "\n",
      "    + Detail: \n",
      "        * Instance: \n",
      "        +-------------------------------------------------+----------------------------------------------+---------+---------+-----------+-----------+-------+-------+----------+\n",
      "        |                                                 |                                              |  Latency (cycles) |   Latency (absolute)  |    Interval   | Pipeline |\n",
      "        |                     Instance                    |                    Module                    |   min   |   max   |    min    |    max    |  min  |  max  |   Type   |\n",
      "        +-------------------------------------------------+----------------------------------------------+---------+---------+-----------+-----------+-------+-------+----------+\n",
      "        |myproject_cifar10_cnn4_U0                        |myproject_cifar10_cnn4                        |     4253|     4253| 21.265 us | 21.265 us |   4099|   4099| dataflow |\n",
      "        |Loop_1_proc459_U0                                |Loop_1_proc459                                |    14337|    14337| 71.685 us | 71.685 us |  14337|  14337|   none   |\n",
      "        |Loop_2_proc_U0                                   |Loop_2_proc                                   |       41|       41|  0.205 us |  0.205 us |     41|     41|   none   |\n",
      "        |Block_myproject_cifar10_cnn4_axi_exit52_proc_U0  |Block_myproject_cifar10_cnn4_axi_exit52_proc  |        0|        0|    0 ns   |    0 ns   |      0|      0|   none   |\n",
      "        +-------------------------------------------------+----------------------------------------------+---------+---------+-----------+-----------+-------+-------+----------+\n",
      "\n",
      "        * Loop: \n",
      "        N/A\n",
      "\n",
      "\n",
      "\n",
      "================================================================\n",
      "== Utilization Estimates\n",
      "================================================================\n",
      "* Summary: \n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "|       Name      | BRAM_18K| DSP48E|   FF   |   LUT  | URAM|\n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "|DSP              |        -|      -|       -|       -|    -|\n",
      "|Expression       |        -|      -|       0|      44|    -|\n",
      "|FIFO             |       12|      -|     349|    1142|    -|\n",
      "|Instance         |      135|    140|   35998|  103995|    0|\n",
      "|Memory           |        -|      -|       -|       -|    -|\n",
      "|Multiplexer      |        -|      -|       -|      90|    -|\n",
      "|Register         |        -|      -|      10|       -|    -|\n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "|Total            |      147|    140|   36357|  105271|    0|\n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "|Available        |      624|   1728|  460800|  230400|   96|\n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "|Utilization (%)  |       23|      8|       7|      45|    0|\n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "\n",
      "+ Detail: \n",
      "    * Instance: \n",
      "    +-------------------------------------------------+----------------------------------------------+---------+-------+-------+--------+-----+\n",
      "    |                     Instance                    |                    Module                    | BRAM_18K| DSP48E|   FF  |   LUT  | URAM|\n",
      "    +-------------------------------------------------+----------------------------------------------+---------+-------+-------+--------+-----+\n",
      "    |Block_myproject_cifar10_cnn4_axi_exit52_proc_U0  |Block_myproject_cifar10_cnn4_axi_exit52_proc  |        0|      0|    162|     193|    0|\n",
      "    |Loop_1_proc459_U0                                |Loop_1_proc459                                |        0|      0|    297|    1703|    0|\n",
      "    |Loop_2_proc_U0                                   |Loop_2_proc                                   |        0|      0|    147|    1031|    0|\n",
      "    |myproject_cifar10_cnn4_U0                        |myproject_cifar10_cnn4                        |      135|    140|  35392|  101068|    0|\n",
      "    +-------------------------------------------------+----------------------------------------------+---------+-------+-------+--------+-----+\n",
      "    |Total                                            |                                              |      135|    140|  35998|  103995|    0|\n",
      "    +-------------------------------------------------+----------------------------------------------+---------+-------+-------+--------+-----+\n",
      "\n",
      "Co-simulation report not found.\n"
     ]
    }
   ],
   "source": [
    "hls4ml.report.read_vivado_report(config['OutputDir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128da6a2",
   "metadata": {},
   "source": [
    "Print the report for the model trained in part 1. Now, compared to the model from part 1, this model has been trained with low-precision quantization, and 75% pruning. You should be able to see that we have saved a lot of resource compared to where we started in part 1. At the same time, referring to the ROC curve above, the model performance is pretty much identical even with this drastic compression!\n",
    "\n",
    "**Note you need to have trained and synthesized the model from part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62b13853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 solution(s) in cifar10-hls-test/myproject_cifar10_cnn_prj.\n",
      "Reports for solution \"solution1\":\n",
      "\n",
      "C simulation report not found.\n",
      "Synthesis report not found.\n",
      "Co-simulation report not found.\n"
     ]
    }
   ],
   "source": [
    "hls4ml.report.read_vivado_report('cifar10-hls-test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821e8bf2",
   "metadata": {},
   "source": [
    "Print the report for the model trained in part 3. Both these models were trained with 75% sparsity, but the new model uses 6-bit precision as well. You can see how Vivado HLS has moved multiplication operations from DSPs into LUTs, reducing the \"critical\" resource usage.\n",
    "\n",
    "**Note you need to have trained and synthesized the model from part 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e77ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls4ml.report.read_vivado_report('cifar10-hls-test3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
